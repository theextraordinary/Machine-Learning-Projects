{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9WFf9XY5rME</td>\n",
       "      <td>24.0</td>\n",
       "      <td>CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REbjfHF0N0s</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Jia &amp; Jackson in the #MOOD\\n\\nProduced by The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hDEc4ImIVHk</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Speaking at the March for Our Lives event in W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JyUKqUTp9rc</td>\n",
       "      <td>26.0</td>\n",
       "      <td>HEY EVERYONE! Today I'm testing out the brand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leu-cTvMWTA</td>\n",
       "      <td>10.0</td>\n",
       "      <td>EXO's Winter Special Album Universe has been r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>C7mxTEskjQg</td>\n",
       "      <td>15.0</td>\n",
       "      <td>In the frozen landscape of the Canadian Arctic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>ARuS950sgXM</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Nikolas Cruz, accused of killing 17 people in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>LU6xDgpnIyM</td>\n",
       "      <td>23.0</td>\n",
       "      <td>Song - Nothing Without You by Dylan Gardner \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>Ye4z35i1b2Q</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>1JXq9779zwU</td>\n",
       "      <td>27.0</td>\n",
       "      <td>Check out our Patreon page: https://www.patreo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  category_id  \\\n",
       "0     9WFf9XY5rME         24.0   \n",
       "1     REbjfHF0N0s         10.0   \n",
       "2     hDEc4ImIVHk         25.0   \n",
       "3     JyUKqUTp9rc         26.0   \n",
       "4     leu-cTvMWTA         10.0   \n",
       "...           ...          ...   \n",
       "5200  C7mxTEskjQg         15.0   \n",
       "5201  ARuS950sgXM         25.0   \n",
       "5202  LU6xDgpnIyM         23.0   \n",
       "5203  Ye4z35i1b2Q         26.0   \n",
       "5204  1JXq9779zwU         27.0   \n",
       "\n",
       "                                            description  \n",
       "0     CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...  \n",
       "1     Jia & Jackson in the #MOOD\\n\\nProduced by The ...  \n",
       "2     Speaking at the March for Our Lives event in W...  \n",
       "3     HEY EVERYONE! Today I'm testing out the brand ...  \n",
       "4     EXO's Winter Special Album Universe has been r...  \n",
       "...                                                 ...  \n",
       "5200  In the frozen landscape of the Canadian Arctic...  \n",
       "5201  Nikolas Cruz, accused of killing 17 people in ...  \n",
       "5202  Song - Nothing Without You by Dylan Gardner \\n...  \n",
       "5203  Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...  \n",
       "5204  Check out our Patreon page: https://www.patreo...  \n",
       "\n",
       "[5205 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories=data['category_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp={}\n",
    "i=0\n",
    "for c in (categories):\n",
    "    temp[c]=i\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{24.0: 0,\n",
       " 10.0: 1,\n",
       " 25.0: 2,\n",
       " 26.0: 3,\n",
       " 23.0: 4,\n",
       " 22.0: 5,\n",
       " 1.0: 6,\n",
       " 2.0: 7,\n",
       " 28.0: 8,\n",
       " 27.0: 9,\n",
       " 17.0: 10,\n",
       " 15.0: 11,\n",
       " 20.0: 12,\n",
       " 19.0: 13,\n",
       " 29.0: 14,\n",
       " 43.0: 15}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['category_id']=data['category_id'].map(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9WFf9XY5rME</td>\n",
       "      <td>0</td>\n",
       "      <td>CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REbjfHF0N0s</td>\n",
       "      <td>1</td>\n",
       "      <td>Jia &amp; Jackson in the #MOOD\\n\\nProduced by The ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hDEc4ImIVHk</td>\n",
       "      <td>2</td>\n",
       "      <td>Speaking at the March for Our Lives event in W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JyUKqUTp9rc</td>\n",
       "      <td>3</td>\n",
       "      <td>HEY EVERYONE! Today I'm testing out the brand ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>leu-cTvMWTA</td>\n",
       "      <td>1</td>\n",
       "      <td>EXO's Winter Special Album Universe has been r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>C7mxTEskjQg</td>\n",
       "      <td>11</td>\n",
       "      <td>In the frozen landscape of the Canadian Arctic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>ARuS950sgXM</td>\n",
       "      <td>2</td>\n",
       "      <td>Nikolas Cruz, accused of killing 17 people in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>LU6xDgpnIyM</td>\n",
       "      <td>4</td>\n",
       "      <td>Song - Nothing Without You by Dylan Gardner \\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>Ye4z35i1b2Q</td>\n",
       "      <td>3</td>\n",
       "      <td>Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>1JXq9779zwU</td>\n",
       "      <td>9</td>\n",
       "      <td>Check out our Patreon page: https://www.patreo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  category_id  \\\n",
       "0     9WFf9XY5rME            0   \n",
       "1     REbjfHF0N0s            1   \n",
       "2     hDEc4ImIVHk            2   \n",
       "3     JyUKqUTp9rc            3   \n",
       "4     leu-cTvMWTA            1   \n",
       "...           ...          ...   \n",
       "5200  C7mxTEskjQg           11   \n",
       "5201  ARuS950sgXM            2   \n",
       "5202  LU6xDgpnIyM            4   \n",
       "5203  Ye4z35i1b2Q            3   \n",
       "5204  1JXq9779zwU            9   \n",
       "\n",
       "                                            description  \n",
       "0     CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...  \n",
       "1     Jia & Jackson in the #MOOD\\n\\nProduced by The ...  \n",
       "2     Speaking at the March for Our Lives event in W...  \n",
       "3     HEY EVERYONE! Today I'm testing out the brand ...  \n",
       "4     EXO's Winter Special Album Universe has been r...  \n",
       "...                                                 ...  \n",
       "5200  In the frozen landscape of the Canadian Arctic...  \n",
       "5201  Nikolas Cruz, accused of killing 17 people in ...  \n",
       "5202  Song - Nothing Without You by Dylan Gardner \\n...  \n",
       "5203  Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...  \n",
       "5204  Check out our Patreon page: https://www.patreo...  \n",
       "\n",
       "[5205 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     1272\n",
       "1      781\n",
       "3      521\n",
       "4      438\n",
       "2      375\n",
       "5      373\n",
       "10     305\n",
       "8      299\n",
       "6      269\n",
       "9      229\n",
       "11     132\n",
       "7       73\n",
       "12      73\n",
       "13      57\n",
       "14       5\n",
       "15       3\n",
       "Name: category_id, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.category_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    3211\n",
       "True     1994\n",
       "Name: video_id, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.video_id.duplicated().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1994 video ids are duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_id=le.fit_transform(data['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['transformed_id']=trans_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59      7\n",
       "683     7\n",
       "2224    6\n",
       "3035    6\n",
       "1894    6\n",
       "       ..\n",
       "1761    1\n",
       "119     1\n",
       "2205    1\n",
       "1983    1\n",
       "1764    1\n",
       "Name: transformed_id, Length: 3211, dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.transformed_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop('video_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>description</th>\n",
       "      <th>transformed_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jia &amp; Jackson in the #MOOD\\n\\nProduced by The ...</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speaking at the March for Our Lives event in W...</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HEY EVERYONE! Today I'm testing out the brand ...</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>EXO's Winter Special Album Universe has been r...</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>11</td>\n",
       "      <td>In the frozen landscape of the Canadian Arctic...</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>2</td>\n",
       "      <td>Nikolas Cruz, accused of killing 17 people in ...</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>4</td>\n",
       "      <td>Song - Nothing Without You by Dylan Gardner \\n...</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>3</td>\n",
       "      <td>Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>9</td>\n",
       "      <td>Check out our Patreon page: https://www.patreo...</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_id                                        description  \\\n",
       "0               0  CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...   \n",
       "1               1  Jia & Jackson in the #MOOD\\n\\nProduced by The ...   \n",
       "2               2  Speaking at the March for Our Lives event in W...   \n",
       "3               3  HEY EVERYONE! Today I'm testing out the brand ...   \n",
       "4               1  EXO's Winter Special Album Universe has been r...   \n",
       "...           ...                                                ...   \n",
       "5200           11  In the frozen landscape of the Canadian Arctic...   \n",
       "5201            2  Nikolas Cruz, accused of killing 17 people in ...   \n",
       "5202            4  Song - Nothing Without You by Dylan Gardner \\n...   \n",
       "5203            3  Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...   \n",
       "5204            9  Check out our Patreon page: https://www.patreo...   \n",
       "\n",
       "      transformed_id  \n",
       "0                515  \n",
       "1               1420  \n",
       "2               2292  \n",
       "3               1046  \n",
       "4               2522  \n",
       "...              ...  \n",
       "5200             648  \n",
       "5201             565  \n",
       "5202            1123  \n",
       "5203            1764  \n",
       "5204             118  \n",
       "\n",
       "[5205 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1b7af968eb0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.transformed_id,data.category_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means it is not necessary that a channel with particular video id can only post similar type of videos. Similar vidoes also has diffrent categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text=[]\n",
    "for sent in data['description']:\n",
    "    temp_str=re.sub(r\"http\\S+\",\" \",sent)\n",
    "    temp_str=re.sub(r\"www\\S+\",\" \",temp_str)\n",
    "    new_text.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop=set(stopwords.words('english'))\n",
    "sno_stem=SnowballStemmer('english')\n",
    "# print(stop)\n",
    "# print(sno_stem.stem('happy'))\n",
    "\n",
    "def cleanhtml(sentence):\n",
    "    patt=re.compile('<.*?>')\n",
    "    clean=re.sub(patt,' ',sentence)\n",
    "    return clean\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won't\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase\n",
    "def cleanpunc(sentence):\n",
    "    clean=re.sub(r'[^A-Za-z0-9]+',' ',sentence)\n",
    "    return clean\n",
    "def cleanalphanum(sentence):\n",
    "    clean=re.sub(\"\\S*\\d\\S*\", \"\", sentence).strip()\n",
    "    return clean\n",
    "\n",
    "\n",
    "def preprocess(sentences):\n",
    "    i=0\n",
    "    prepro_reviews=[]\n",
    "    for sent in sentences.values:\n",
    "        sent=cleanhtml(sent)\n",
    "        sent=cleanpunc(sent)\n",
    "        sent=cleanalphanum(sent)\n",
    "        sent=decontracted(sent)\n",
    "        words=[]\n",
    "        for word in sent.split(\" \"):\n",
    "            if word not in stop:\n",
    "                s=sno_stem.stem(word.lower()).encode('utf8')\n",
    "                words.append(s)\n",
    "        sent=b\" \".join(words)\n",
    "        prepro_reviews.append(sent)\n",
    "        i+=1\n",
    "    #print(prepro_reviews)\n",
    "    return prepro_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(sentences):\n",
    "    prepro_reviews=preprocess(sentences)\n",
    "    list_of_sentence=[]\n",
    "    for sentence in prepro_reviews:\n",
    "        list_of_sentence.append(sentence.decode().split())\n",
    "    # for sent in list_of_sentence:\n",
    "    #     for word in sent:\n",
    "    #print(list_of_sentence)\n",
    "    return list_of_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences=pd.Series(new_text)\n",
    "prepro_text=preprocess2(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['click',\n",
       " 'to',\n",
       " 'subscrib',\n",
       " 'to',\n",
       " 'the',\n",
       " 'youtub',\n",
       " 'in',\n",
       " 'this',\n",
       " 'episod',\n",
       " 'a',\n",
       " 'video',\n",
       " 'to',\n",
       " 'tri',\n",
       " 'to',\n",
       " 'get',\n",
       " 'the',\n",
       " 'reactor',\n",
       " 'to',\n",
       " 'laugh',\n",
       " 'laughchalleng',\n",
       " 'fbeteam',\n",
       " 'com',\n",
       " 'npleas',\n",
       " 'watch',\n",
       " 'subscrib',\n",
       " 'creator',\n",
       " 'featur',\n",
       " 'episod',\n",
       " 'then',\n",
       " 'hit',\n",
       " 'the',\n",
       " 'new',\n",
       " 'video',\n",
       " 'pt',\n",
       " 'react',\n",
       " 'seri',\n",
       " 'watch',\n",
       " 'latest',\n",
       " 'video',\n",
       " 'fbe',\n",
       " 'n',\n",
       " 'nyoutub',\n",
       " 'tri',\n",
       " 'smile',\n",
       " 'laugh',\n",
       " 'see',\n",
       " 'reaction',\n",
       " 'laugh',\n",
       " 'challeng',\n",
       " 'n',\n",
       " 'ncontent',\n",
       " 'featur',\n",
       " 'episod',\n",
       " 'nserious',\n",
       " 'n',\n",
       " 'feel',\n",
       " 'cone',\n",
       " 'head',\n",
       " 'n',\n",
       " 'sourc',\n",
       " 'nfrom',\n",
       " 'kirin',\n",
       " 'j',\n",
       " 'callinan',\n",
       " 'big',\n",
       " 'enough',\n",
       " 'n',\n",
       " 'lyric',\n",
       " 'n',\n",
       " 'galaxi',\n",
       " 'n',\n",
       " 'batteri',\n",
       " 'n',\n",
       " 'seem',\n",
       " 'cabbag',\n",
       " 'patch',\n",
       " 'babi',\n",
       " 'vine',\n",
       " 'n',\n",
       " 'goal',\n",
       " 'credit',\n",
       " 'origin',\n",
       " 'link',\n",
       " 'content',\n",
       " 'featur',\n",
       " 'show',\n",
       " 'if',\n",
       " 'see',\n",
       " 'incorrect',\n",
       " 'miss',\n",
       " 'attribut',\n",
       " 'pleas',\n",
       " 'reach',\n",
       " 'credit',\n",
       " 'fbeteam',\n",
       " 'com',\n",
       " 'n',\n",
       " 'nthis',\n",
       " 'episod',\n",
       " 'featur',\n",
       " 'follow',\n",
       " 'youtub',\n",
       " 'nkeith',\n",
       " 'habersberg',\n",
       " 'becki',\n",
       " 'n',\n",
       " 'wassabi',\n",
       " 'n',\n",
       " 'outlet',\n",
       " 'n',\n",
       " 'villa',\n",
       " 'n',\n",
       " 'mielniczenko',\n",
       " 'n',\n",
       " 'hart',\n",
       " 'n',\n",
       " 'nygaard',\n",
       " 'n',\n",
       " 'william',\n",
       " 'n',\n",
       " 'fine',\n",
       " 'brother',\n",
       " 'entertain',\n",
       " 'nfbe',\n",
       " 'websit',\n",
       " 'channel',\n",
       " 'channel',\n",
       " 'channel',\n",
       " 'podcast',\n",
       " 'play',\n",
       " 'podcast',\n",
       " 'fbe',\n",
       " 'ntwitch',\n",
       " 'us',\n",
       " 'stuff',\n",
       " 'nfbe',\n",
       " 'np',\n",
       " 'o',\n",
       " 'box',\n",
       " 'nvalley',\n",
       " 'villag',\n",
       " 'ca',\n",
       " 'n',\n",
       " 'nexecut',\n",
       " 'produc',\n",
       " 'benni',\n",
       " 'fine',\n",
       " 'rafi',\n",
       " 'fine',\n",
       " 'nhead',\n",
       " 'post',\n",
       " 'product',\n",
       " 'nick',\n",
       " 'bergthold',\n",
       " 'ndirector',\n",
       " 'product',\n",
       " 'drew',\n",
       " 'roder',\n",
       " 'ndigit',\n",
       " 'product',\n",
       " 'manag',\n",
       " 'andrew',\n",
       " 'chang',\n",
       " 'nsupervis',\n",
       " 'produc',\n",
       " 'vincent',\n",
       " 'ieraci',\n",
       " 'nproduc',\n",
       " 'alyssa',\n",
       " 'carter',\n",
       " 'nproduct',\n",
       " 'coordin',\n",
       " 'cynthia',\n",
       " 'garcia',\n",
       " 'nassist',\n",
       " 'product',\n",
       " 'coordin',\n",
       " 'kristi',\n",
       " 'kiefer',\n",
       " 'nstudio',\n",
       " 'technician',\n",
       " 'josh',\n",
       " 'hilton',\n",
       " 'nproduct',\n",
       " 'assist',\n",
       " 'kenira',\n",
       " 'moor',\n",
       " 'jayden',\n",
       " 'romero',\n",
       " 'oscar',\n",
       " 'ramo',\n",
       " 'stephen',\n",
       " 'miller',\n",
       " 'lauren',\n",
       " 'hutchinson',\n",
       " 'kylli',\n",
       " 'jahn',\n",
       " 'neditor',\n",
       " 'chris',\n",
       " 'hayn',\n",
       " 'nassist',\n",
       " 'editor',\n",
       " 'austin',\n",
       " 'miller',\n",
       " 'andr',\n",
       " 'garder',\n",
       " 'ndirector',\n",
       " 'post',\n",
       " 'adam',\n",
       " 'spea',\n",
       " 'npost',\n",
       " 'supervisor',\n",
       " 'david',\n",
       " 'valbuena',\n",
       " 'nset',\n",
       " 'design',\n",
       " 'melissa',\n",
       " 'judson',\n",
       " 'ngraphic',\n",
       " 'anim',\n",
       " 'will',\n",
       " 'hyler',\n",
       " 'ntheme',\n",
       " 'music',\n",
       " 'cyrus',\n",
       " 'ghahremani',\n",
       " 'n',\n",
       " 'n',\n",
       " 'fine',\n",
       " 'brother',\n",
       " 'entertain',\n",
       " 'n',\n",
       " 'nyoutub',\n",
       " 'react',\n",
       " 'tri',\n",
       " 'watch',\n",
       " 'this',\n",
       " 'without',\n",
       " 'laugh',\n",
       " 'grin']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepro_text[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['preprocessed_desc']=prepro_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category_id</th>\n",
       "      <th>description</th>\n",
       "      <th>transformed_id</th>\n",
       "      <th>preprocessed_desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...</td>\n",
       "      <td>515</td>\n",
       "      <td>[click, to, subscrib, to, the, youtub, in, thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Jia &amp; Jackson in the #MOOD\\n\\nProduced by The ...</td>\n",
       "      <td>1420</td>\n",
       "      <td>[jia, jackson, mood, n, nproduc, the, partysqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speaking at the March for Our Lives event in W...</td>\n",
       "      <td>2292</td>\n",
       "      <td>[speak, march, our, live, event, washington, m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>HEY EVERYONE! Today I'm testing out the brand ...</td>\n",
       "      <td>1046</td>\n",
       "      <td>[hey, everyon, today, i, test, brand, new, col...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>EXO's Winter Special Album Universe has been r...</td>\n",
       "      <td>2522</td>\n",
       "      <td>[exo, winter, special, album, univers, releas,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>11</td>\n",
       "      <td>In the frozen landscape of the Canadian Arctic...</td>\n",
       "      <td>648</td>\n",
       "      <td>[in, frozen, landscap, canadian, arctic, one, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>2</td>\n",
       "      <td>Nikolas Cruz, accused of killing 17 people in ...</td>\n",
       "      <td>565</td>\n",
       "      <td>[nikola, cruz, accus, kill, peopl, parkland, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>4</td>\n",
       "      <td>Song - Nothing Without You by Dylan Gardner \\n...</td>\n",
       "      <td>1123</td>\n",
       "      <td>[song, noth, without, you, dylan, gardner, nit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>3</td>\n",
       "      <td>Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...</td>\n",
       "      <td>1764</td>\n",
       "      <td>[subscrib, here, funni, coupl, prank, prank, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>9</td>\n",
       "      <td>Check out our Patreon page: https://www.patreo...</td>\n",
       "      <td>118</td>\n",
       "      <td>[check, patreon, page, full, lesson, unman, na...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      category_id                                        description  \\\n",
       "0               0  CLICK TO SUBSCRIBE TO THE YOUTUBERS IN THIS EP...   \n",
       "1               1  Jia & Jackson in the #MOOD\\n\\nProduced by The ...   \n",
       "2               2  Speaking at the March for Our Lives event in W...   \n",
       "3               3  HEY EVERYONE! Today I'm testing out the brand ...   \n",
       "4               1  EXO's Winter Special Album Universe has been r...   \n",
       "...           ...                                                ...   \n",
       "5200           11  In the frozen landscape of the Canadian Arctic...   \n",
       "5201            2  Nikolas Cruz, accused of killing 17 people in ...   \n",
       "5202            4  Song - Nothing Without You by Dylan Gardner \\n...   \n",
       "5203            3  Subscribe Here: http://bit.ly/2uaz0on\\n12 Funn...   \n",
       "5204            9  Check out our Patreon page: https://www.patreo...   \n",
       "\n",
       "      transformed_id                                  preprocessed_desc  \n",
       "0                515  [click, to, subscrib, to, the, youtub, in, thi...  \n",
       "1               1420  [jia, jackson, mood, n, nproduc, the, partysqu...  \n",
       "2               2292  [speak, march, our, live, event, washington, m...  \n",
       "3               1046  [hey, everyon, today, i, test, brand, new, col...  \n",
       "4               2522  [exo, winter, special, album, univers, releas,...  \n",
       "...              ...                                                ...  \n",
       "5200             648  [in, frozen, landscap, canadian, arctic, one, ...  \n",
       "5201             565  [nikola, cruz, accus, kill, peopl, parkland, f...  \n",
       "5202            1123  [song, noth, without, you, dylan, gardner, nit...  \n",
       "5203            1764  [subscrib, here, funni, coupl, prank, prank, w...  \n",
       "5204             118  [check, patreon, page, full, lesson, unman, na...  \n",
       "\n",
       "[5205 rows x 4 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the sentences to tfidf - word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=Word2Vec(prepro_text,min_count=6,size=50, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84908247"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('girl','boy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.50519425, -0.07825918, -0.18435396, -0.4755037 , -0.24152566,\n",
       "        0.23351912,  0.25570056, -0.36471078, -0.17988594,  0.05163268,\n",
       "       -0.570078  , -0.4208055 ,  0.4868832 , -0.7781154 , -0.11176485,\n",
       "       -0.35456052, -0.0202883 ,  0.64694196, -0.0029078 ,  0.12015936,\n",
       "       -0.33451426,  0.02228179, -0.48766124, -0.15339842, -0.31125966,\n",
       "        0.08822977,  0.5359767 , -0.31394756,  0.30054003, -0.55021614,\n",
       "        0.52987427, -0.3793774 ,  0.21263412,  0.2735904 ,  0.5772743 ,\n",
       "        0.32904568, -0.1881475 ,  0.14500637,  0.38683394,  0.08990692,\n",
       "        0.41810828,  0.2096734 ,  0.3527697 ,  0.03880199,  0.16152881,\n",
       "        0.62092304, -0.31396306, -0.03803546, -0.3563921 ,  0.9088048 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv['boy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_words = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Now each word is mapped to a vector of size 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm  # Used to create progress bars\n",
    "model = TfidfVectorizer()\n",
    "model.fit(preprocess(sentences))\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))\n",
    "tfidf_feat = model.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aabi',\n",
       " 'aafghani',\n",
       " 'aaliyah',\n",
       " 'aaliyahxo',\n",
       " 'aam',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abalo',\n",
       " 'abandon',\n",
       " 'abba',\n",
       " 'abbey',\n",
       " 'abbi',\n",
       " 'abbrevi',\n",
       " 'abc',\n",
       " 'abcv',\n",
       " 'abdallah',\n",
       " 'abdelwahab',\n",
       " 'abdom',\n",
       " 'abdulla',\n",
       " 'abdullah',\n",
       " 'abdulmateen',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'abelardo',\n",
       " 'abenir',\n",
       " 'abhijit',\n",
       " 'abid',\n",
       " 'abigail',\n",
       " 'abil',\n",
       " 'abl',\n",
       " 'ablaz',\n",
       " 'aboah',\n",
       " 'aboard',\n",
       " 'abonnez',\n",
       " 'abort',\n",
       " 'about',\n",
       " 'abov',\n",
       " 'abovitz',\n",
       " 'abqd',\n",
       " 'abraham',\n",
       " 'abram',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abseil',\n",
       " 'absent',\n",
       " 'absolu',\n",
       " 'absolut',\n",
       " 'absorb',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'abu',\n",
       " 'abud',\n",
       " 'abund',\n",
       " 'abus',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'acaba',\n",
       " 'acabado',\n",
       " 'academ',\n",
       " 'academi',\n",
       " 'academia',\n",
       " 'acanthus',\n",
       " 'acc',\n",
       " 'acceler',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'access',\n",
       " 'accessori',\n",
       " 'accid',\n",
       " 'accident',\n",
       " 'acclaim',\n",
       " 'accommod',\n",
       " 'accompani',\n",
       " 'accomplish',\n",
       " 'accord',\n",
       " 'account',\n",
       " 'accumul',\n",
       " 'accur',\n",
       " 'accus',\n",
       " 'ace',\n",
       " 'acefamili',\n",
       " 'acercado',\n",
       " 'aceton',\n",
       " 'ach',\n",
       " 'achiev',\n",
       " 'achok',\n",
       " 'acid',\n",
       " 'acima',\n",
       " 'acknowledg',\n",
       " 'acn',\n",
       " 'aconteceu',\n",
       " 'acoust',\n",
       " 'acquaint',\n",
       " 'acquir',\n",
       " 'acr',\n",
       " 'acreditado',\n",
       " 'acrobat',\n",
       " 'acromegali',\n",
       " 'across',\n",
       " 'acryl',\n",
       " 'acsen',\n",
       " 'act',\n",
       " 'actinid',\n",
       " 'action',\n",
       " 'activ',\n",
       " 'activatemanag',\n",
       " 'activist',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actual',\n",
       " 'actuat',\n",
       " 'acwel',\n",
       " 'ad',\n",
       " 'adair',\n",
       " 'adam',\n",
       " 'adamortiz',\n",
       " 'adamruinseveryth',\n",
       " 'adapt',\n",
       " 'add',\n",
       " 'addict',\n",
       " 'addison',\n",
       " 'addit',\n",
       " 'address',\n",
       " 'adel',\n",
       " 'adelaid',\n",
       " 'adelain',\n",
       " 'adelainemorin',\n",
       " 'adelman',\n",
       " 'aderinto',\n",
       " 'adey',\n",
       " 'adhes',\n",
       " 'adi',\n",
       " 'adick',\n",
       " 'adida',\n",
       " 'adil',\n",
       " 'adjust',\n",
       " 'adler',\n",
       " 'admet',\n",
       " 'admin',\n",
       " 'administ',\n",
       " 'administr',\n",
       " 'admir',\n",
       " 'admiss',\n",
       " 'admit',\n",
       " 'admoni',\n",
       " 'adnarimnavi',\n",
       " 'ado',\n",
       " 'adob',\n",
       " 'adopt',\n",
       " 'ador',\n",
       " 'adorn',\n",
       " 'adria',\n",
       " 'adriaensen',\n",
       " 'adriana',\n",
       " 'adriat',\n",
       " 'adric',\n",
       " 'adrien',\n",
       " 'adrienelouis',\n",
       " 'adrienn',\n",
       " 'adrift',\n",
       " 'adshead',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adultolesc',\n",
       " 'adv',\n",
       " 'advanc',\n",
       " 'advantag',\n",
       " 'advent',\n",
       " 'adventur',\n",
       " 'adventuresom',\n",
       " 'advert',\n",
       " 'advertis',\n",
       " 'advertori',\n",
       " 'advic',\n",
       " 'advis',\n",
       " 'advisor',\n",
       " 'advisori',\n",
       " 'advoc',\n",
       " 'advocaci',\n",
       " 'adwoa',\n",
       " 'adz',\n",
       " 'aeri',\n",
       " 'aerobat',\n",
       " 'aerospac',\n",
       " 'aesthet',\n",
       " 'aeton',\n",
       " 'af',\n",
       " 'afa',\n",
       " 'afanasjeva',\n",
       " 'afantano',\n",
       " 'afc',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affili',\n",
       " 'affirm',\n",
       " 'affleck',\n",
       " 'afford',\n",
       " 'afi',\n",
       " 'afici',\n",
       " 'aficionado',\n",
       " 'afoot',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'afriqu',\n",
       " 'afrojack',\n",
       " 'after',\n",
       " 'afterglow',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftershav',\n",
       " 'aftershow',\n",
       " 'afterward',\n",
       " 'aftra',\n",
       " 'ag',\n",
       " 'again',\n",
       " 'agdao',\n",
       " 'age',\n",
       " 'ageless',\n",
       " 'agenc',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggreg',\n",
       " 'aggress',\n",
       " 'agich',\n",
       " 'agier',\n",
       " 'agil',\n",
       " 'agl',\n",
       " 'agnolotti',\n",
       " 'ago',\n",
       " 'agoodnight',\n",
       " 'agora',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'agress',\n",
       " 'agro',\n",
       " 'agua',\n",
       " 'aguilar',\n",
       " 'aguilera',\n",
       " 'aguirr',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahmad',\n",
       " 'ahora',\n",
       " 'ahuja',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aidi',\n",
       " 'aiea',\n",
       " 'aif',\n",
       " 'aih',\n",
       " 'aiken',\n",
       " 'aikin',\n",
       " 'aiko',\n",
       " 'ailment',\n",
       " 'aim',\n",
       " 'aiman',\n",
       " 'aimez',\n",
       " 'ain',\n",
       " 'aina',\n",
       " 'ainsley',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airbnb',\n",
       " 'airbrush',\n",
       " 'airbus',\n",
       " 'aircraft',\n",
       " 'airi',\n",
       " 'airlift',\n",
       " 'airlin',\n",
       " 'airman',\n",
       " 'airplan',\n",
       " 'airpod',\n",
       " 'airport',\n",
       " 'airspun',\n",
       " 'airtight',\n",
       " 'airwav',\n",
       " 'ais',\n",
       " 'aisha',\n",
       " 'aisl',\n",
       " 'aispuro',\n",
       " 'aitan',\n",
       " 'aitchison',\n",
       " 'aiy',\n",
       " 'aj',\n",
       " 'aja',\n",
       " 'ajax',\n",
       " 'ajay',\n",
       " 'ajinkya',\n",
       " 'ajiri',\n",
       " 'ajit',\n",
       " 'ajn',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akademik',\n",
       " 'akana',\n",
       " 'akerman',\n",
       " 'akin',\n",
       " 'akira',\n",
       " 'akkai',\n",
       " 'akpanudosen',\n",
       " 'akpolo',\n",
       " 'akubez',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alabamian',\n",
       " 'alabast',\n",
       " 'alan',\n",
       " 'alana',\n",
       " 'alarcon',\n",
       " 'alarm',\n",
       " 'alasdair',\n",
       " 'alasiri',\n",
       " 'alaska',\n",
       " 'alastair',\n",
       " 'alba',\n",
       " 'albani',\n",
       " 'albatross',\n",
       " 'alberini',\n",
       " 'albert',\n",
       " 'alberto',\n",
       " 'albrecht',\n",
       " 'album',\n",
       " 'albuquerqu',\n",
       " 'alcantara',\n",
       " 'alcohol',\n",
       " 'alcuni',\n",
       " 'alda',\n",
       " 'aldavaz',\n",
       " 'aldo',\n",
       " 'aldridg',\n",
       " 'ale',\n",
       " 'alec',\n",
       " 'alecsteel',\n",
       " 'alegria',\n",
       " 'alejandro',\n",
       " 'alek',\n",
       " 'aleksandar',\n",
       " 'alert',\n",
       " 'alessandra',\n",
       " 'alessandralorenn',\n",
       " 'alessandro',\n",
       " 'alessia',\n",
       " 'alesso',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexand',\n",
       " 'alexandr',\n",
       " 'alexandra',\n",
       " 'alexandrina',\n",
       " 'alexandru',\n",
       " 'alexi',\n",
       " 'alexjon',\n",
       " 'alfa',\n",
       " 'alfr',\n",
       " 'alga',\n",
       " 'algebra',\n",
       " 'alghamdi',\n",
       " 'algonquin',\n",
       " 'algorithm',\n",
       " 'algun',\n",
       " 'alhambra',\n",
       " 'alhazzaa',\n",
       " 'alhulail',\n",
       " 'ali',\n",
       " 'alibaba',\n",
       " 'alic',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienist',\n",
       " 'align',\n",
       " 'alik',\n",
       " 'alile',\n",
       " 'alina',\n",
       " 'aliouch',\n",
       " 'alisha',\n",
       " 'alishamari',\n",
       " 'alison',\n",
       " 'alissa',\n",
       " 'alita',\n",
       " 'aliv',\n",
       " 'aliyya',\n",
       " 'aliza',\n",
       " 'aljagbir',\n",
       " 'alkali',\n",
       " 'alkhatib',\n",
       " 'alkhulaifi',\n",
       " 'all',\n",
       " 'allan',\n",
       " 'allana',\n",
       " 'alleg',\n",
       " 'allegan',\n",
       " 'allegi',\n",
       " 'allegr',\n",
       " 'allegro',\n",
       " 'allen',\n",
       " 'allerg',\n",
       " 'alley',\n",
       " 'allfallsdown',\n",
       " 'alli',\n",
       " 'allianc',\n",
       " 'allianz',\n",
       " 'alliegbeauti',\n",
       " 'alliegpalett',\n",
       " 'allig',\n",
       " 'allison',\n",
       " 'alloutwar',\n",
       " 'allow',\n",
       " 'allrecip',\n",
       " 'allstar',\n",
       " 'allthat',\n",
       " 'alltta',\n",
       " 'allur',\n",
       " 'allysa',\n",
       " 'alma',\n",
       " 'almagu',\n",
       " 'almanac',\n",
       " 'almazankitchen',\n",
       " 'almeda',\n",
       " 'almellehan',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'alo',\n",
       " 'alon',\n",
       " 'along',\n",
       " 'alongsid',\n",
       " 'alot',\n",
       " 'alpert',\n",
       " 'alpha',\n",
       " 'alphacat',\n",
       " 'alpin',\n",
       " 'alrdridg',\n",
       " 'alreadi',\n",
       " 'alright',\n",
       " 'alsemgeest',\n",
       " 'also',\n",
       " 'alsop',\n",
       " 'alt',\n",
       " 'alter',\n",
       " 'altern',\n",
       " 'although',\n",
       " 'altitud',\n",
       " 'altman',\n",
       " 'alto',\n",
       " 'altogeth',\n",
       " 'altonaga',\n",
       " 'altraid',\n",
       " 'altuwaijri',\n",
       " 'alucia',\n",
       " 'alum',\n",
       " 'aluminium',\n",
       " 'aluminum',\n",
       " 'alv',\n",
       " 'alvarado',\n",
       " 'alvarez',\n",
       " 'alvaro',\n",
       " 'alveoli',\n",
       " 'alverez',\n",
       " 'alvey',\n",
       " 'alvin',\n",
       " 'alvinnn',\n",
       " 'alvord',\n",
       " 'alway',\n",
       " 'alwin',\n",
       " 'alyssa',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amadeus',\n",
       " 'amahl',\n",
       " 'amanda',\n",
       " 'amangiri',\n",
       " 'amant',\n",
       " 'amapola',\n",
       " 'amara',\n",
       " 'amaranth',\n",
       " 'amari',\n",
       " 'amarillo',\n",
       " 'amarxistphil',\n",
       " 'amateur',\n",
       " 'amaz',\n",
       " 'amazebal',\n",
       " 'amazon',\n",
       " 'amazonian',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'amberschol',\n",
       " 'ambient',\n",
       " 'ambit',\n",
       " 'ambiti',\n",
       " 'ambl',\n",
       " 'amblin',\n",
       " 'ambul',\n",
       " 'ambush',\n",
       " 'amc',\n",
       " 'ameen',\n",
       " 'amel',\n",
       " 'amelia',\n",
       " 'amelior',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'amendolar',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americatvletsplay',\n",
       " 'amg',\n",
       " 'ami',\n",
       " 'amick',\n",
       " 'amico',\n",
       " 'amid',\n",
       " 'amiibo',\n",
       " 'amir',\n",
       " 'amityvill',\n",
       " 'aml',\n",
       " 'ammar',\n",
       " 'amnesia',\n",
       " 'amo',\n",
       " 'amol',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amor',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'amphibian',\n",
       " 'amphitheat',\n",
       " 'amphitheatr',\n",
       " 'ampitheatr',\n",
       " 'amritsar',\n",
       " 'amrul',\n",
       " 'amsterdam',\n",
       " 'amtrak',\n",
       " 'amuka',\n",
       " 'amus',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anacita',\n",
       " 'anaheim',\n",
       " 'anai',\n",
       " 'anakin',\n",
       " 'analog',\n",
       " 'analogu',\n",
       " 'analys',\n",
       " 'analysi',\n",
       " 'analyt',\n",
       " 'analytica',\n",
       " 'analyz',\n",
       " 'anand',\n",
       " 'anarchi',\n",
       " 'anastasia',\n",
       " 'anatom',\n",
       " 'anatomi',\n",
       " 'ancestor',\n",
       " 'ancestri',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'and',\n",
       " 'andant',\n",
       " 'andaya',\n",
       " 'andddd',\n",
       " 'ander',\n",
       " 'andersen',\n",
       " 'anderson',\n",
       " 'andersson',\n",
       " 'andi',\n",
       " 'andor',\n",
       " 'andow',\n",
       " 'andr',\n",
       " 'andra',\n",
       " 'andrea',\n",
       " 'andreassen',\n",
       " 'andrei',\n",
       " 'andrej',\n",
       " 'andrethegi',\n",
       " 'andrew',\n",
       " 'andrewdeast',\n",
       " 'andrewstwitt',\n",
       " 'andrewturnsdown',\n",
       " 'andrey',\n",
       " 'android',\n",
       " 'anecdot',\n",
       " 'aneurysm',\n",
       " 'ang',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angelea',\n",
       " 'angelina',\n",
       " 'anger',\n",
       " 'angi',\n",
       " 'angl',\n",
       " 'anglerfish',\n",
       " 'angri',\n",
       " 'angrybirdsmatch',\n",
       " 'anh',\n",
       " 'ani',\n",
       " 'anika',\n",
       " 'anim',\n",
       " 'animatron',\n",
       " 'animoji',\n",
       " 'aniston',\n",
       " 'anitta',\n",
       " 'anker',\n",
       " 'ankl',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'annaakana',\n",
       " 'annabell',\n",
       " 'annalora',\n",
       " 'annalynn',\n",
       " 'annamaria',\n",
       " 'annapurna',\n",
       " 'annasophia',\n",
       " 'annemari',\n",
       " 'annemariemus',\n",
       " 'annett',\n",
       " 'anni',\n",
       " 'annihil',\n",
       " 'anniversari',\n",
       " 'annouc',\n",
       " 'announc',\n",
       " 'annoy',\n",
       " 'annual',\n",
       " 'annuar',\n",
       " 'anolini',\n",
       " 'anonym',\n",
       " 'anoplolepi',\n",
       " 'anoth',\n",
       " 'ansel',\n",
       " 'anson',\n",
       " 'answer',\n",
       " 'ant',\n",
       " 'antarct',\n",
       " 'antarctica',\n",
       " 'antetokounmpo',\n",
       " 'anthem',\n",
       " 'antholog',\n",
       " 'anthoni',\n",
       " 'anthonygargiula',\n",
       " 'anthropocen',\n",
       " 'anthropolog',\n",
       " 'anti',\n",
       " 'antibiot',\n",
       " 'antibodi',\n",
       " 'antic',\n",
       " 'anticip',\n",
       " 'antidot',\n",
       " 'antigen',\n",
       " 'antimoni',\n",
       " 'antiqu',\n",
       " 'antoin',\n",
       " 'anton',\n",
       " 'antoni',\n",
       " 'antonio',\n",
       " 'antonyan',\n",
       " 'antscanada',\n",
       " 'antwerp',\n",
       " 'anuj',\n",
       " 'anuka',\n",
       " 'anwar',\n",
       " 'anxieti',\n",
       " 'anxious',\n",
       " 'anya',\n",
       " 'anybodi',\n",
       " 'anymor',\n",
       " 'anyon',\n",
       " 'anyth',\n",
       " 'anytim',\n",
       " 'anyway',\n",
       " 'anywher',\n",
       " 'anz',\n",
       " 'anzivino',\n",
       " 'ao',\n",
       " 'aoi',\n",
       " 'aoki',\n",
       " 'ap',\n",
       " 'apa',\n",
       " 'aparec',\n",
       " 'aparent',\n",
       " 'apart',\n",
       " 'apasionado',\n",
       " 'apathi',\n",
       " 'ape',\n",
       " 'apertur',\n",
       " 'apesar',\n",
       " 'apm',\n",
       " 'apocalyps',\n",
       " 'apoge',\n",
       " 'apollo',\n",
       " 'apolog',\n",
       " 'apologis',\n",
       " 'app',\n",
       " 'appar',\n",
       " 'apparel',\n",
       " 'appeal',\n",
       " 'appear',\n",
       " 'appeas',\n",
       " 'appendix',\n",
       " 'appetit',\n",
       " 'appl',\n",
       " 'applaud',\n",
       " 'applaus',\n",
       " 'applemus',\n",
       " 'applepi',\n",
       " 'applese',\n",
       " 'appli',\n",
       " 'applic',\n",
       " 'appoint',\n",
       " 'appreci',\n",
       " 'apprentic',\n",
       " 'approach',\n",
       " 'appropri',\n",
       " 'approv',\n",
       " 'approxim',\n",
       " 'apr',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aptak',\n",
       " 'aptitud',\n",
       " 'apyrodesign',\n",
       " 'aqeel',\n",
       " 'aqu',\n",
       " 'aqua',\n",
       " 'aquaman',\n",
       " 'aquarium',\n",
       " 'aquascap',\n",
       " 'aqui',\n",
       " 'aquietplac',\n",
       " 'aquilina',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'aragon',\n",
       " 'aranda',\n",
       " 'arashiyama',\n",
       " 'arbitr',\n",
       " 'arboretum',\n",
       " 'arbuckl',\n",
       " 'arc',\n",
       " 'arcad',\n",
       " 'arcaini',\n",
       " 'arcainiiii',\n",
       " 'arch',\n",
       " 'archaeologist',\n",
       " 'archeologico',\n",
       " 'archer',\n",
       " 'archi',\n",
       " 'archibishop',\n",
       " 'architectur',\n",
       " 'archiv',\n",
       " 'archivist',\n",
       " 'archuleta',\n",
       " 'arctic',\n",
       " 'arden',\n",
       " 'arduino',\n",
       " 'are',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'arevalo',\n",
       " 'areyouwithus',\n",
       " 'argentin',\n",
       " 'argentina',\n",
       " 'argon',\n",
       " 'argu',\n",
       " 'arguabl',\n",
       " 'arguell',\n",
       " 'argument',\n",
       " 'ari',\n",
       " 'aria',\n",
       " 'ariana',\n",
       " 'ariel',\n",
       " 'ariell',\n",
       " 'arikare',\n",
       " 'arikareean',\n",
       " 'arisa',\n",
       " 'aristocraci',\n",
       " 'aristocrat',\n",
       " 'aritaum',\n",
       " 'ariza',\n",
       " 'arizona',\n",
       " 'arjen',\n",
       " 'arjona',\n",
       " 'ark',\n",
       " 'arkadiy',\n",
       " 'arkansa',\n",
       " 'arlook',\n",
       " 'arm',\n",
       " 'armando',\n",
       " 'armani',\n",
       " 'armengol',\n",
       " 'armi',\n",
       " 'armisen',\n",
       " 'armori',\n",
       " 'armpit',\n",
       " 'armstrong',\n",
       " 'arnaud',\n",
       " 'arnold',\n",
       " 'arntzen',\n",
       " 'aronian',\n",
       " 'around',\n",
       " 'arpaio',\n",
       " 'arpel',\n",
       " 'arpita',\n",
       " 'arr',\n",
       " 'arra',\n",
       " 'arraign',\n",
       " 'arrancado',\n",
       " 'arrang',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arri',\n",
       " 'arriba',\n",
       " 'arriola',\n",
       " 'arriv',\n",
       " 'arriveth',\n",
       " 'arrog',\n",
       " 'arrow',\n",
       " 'arsenal',\n",
       " 'arsenic',\n",
       " 'arslan',\n",
       " 'art',\n",
       " 'artbeatz',\n",
       " 'artemi',\n",
       " 'arthur',\n",
       " 'articl',\n",
       " 'artifact',\n",
       " 'artifici',\n",
       " 'artisan',\n",
       " 'artist',\n",
       " 'artista',\n",
       " 'artisthowel',\n",
       " 'artistool',\n",
       " 'artistri',\n",
       " 'artlist',\n",
       " 'artpark',\n",
       " 'artwork',\n",
       " 'arun',\n",
       " 'arunabh',\n",
       " 'arviso',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'asapsci',\n",
       " 'asar',\n",
       " 'asburi',\n",
       " 'asc',\n",
       " 'ascap',\n",
       " 'ascenso',\n",
       " 'ascot',\n",
       " 'asean',\n",
       " 'ash',\n",
       " 'asham',\n",
       " 'ashanti',\n",
       " 'asher',\n",
       " 'ashevill',\n",
       " 'ashland',\n",
       " 'ashleigh',\n",
       " 'ashley',\n",
       " 'ashleyi',\n",
       " 'ashmor',\n",
       " 'ashton',\n",
       " 'ashtray',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asianaesingstooyouu',\n",
       " 'asifitsyourlast',\n",
       " 'asiryan',\n",
       " 'ask',\n",
       " 'askew',\n",
       " 'askhermor',\n",
       " 'aslan',\n",
       " 'asleep',\n",
       " 'asmr',\n",
       " 'asmrdarl',\n",
       " 'aso',\n",
       " 'aspect',\n",
       " 'aspen',\n",
       " 'asphalt',\n",
       " 'aspic',\n",
       " 'aspir',\n",
       " 'asprir',\n",
       " 'ass',\n",
       " 'assaf',\n",
       " 'assassin',\n",
       " 'assault',\n",
       " 'assembl',\n",
       " 'assent',\n",
       " 'assert',\n",
       " 'assess',\n",
       " 'asset',\n",
       " 'asshol',\n",
       " 'assi',\n",
       " 'assign',\n",
       " 'assim',\n",
       " 'assist',\n",
       " 'associ',\n",
       " 'assum',\n",
       " 'assumpt',\n",
       " 'assur',\n",
       " 'astatin',\n",
       " 'aster',\n",
       " 'asterisk',\n",
       " 'asteroid',\n",
       " 'asthma',\n",
       " 'astia',\n",
       " 'aston',\n",
       " 'astonish',\n",
       " 'astori',\n",
       " 'astound',\n",
       " 'astralwerk',\n",
       " 'astray',\n",
       " 'astro',\n",
       " 'astrolog',\n",
       " 'astronaut',\n",
       " 'astronom',\n",
       " 'astronomi',\n",
       " 'astrophysicist',\n",
       " 'asus',\n",
       " 'asylum',\n",
       " 'asymmetr',\n",
       " 'asynchron',\n",
       " 'at',\n",
       " 'atamanuik',\n",
       " 'atari',\n",
       " 'ate',\n",
       " 'athen',\n",
       " 'athenian',\n",
       " 'athlet',\n",
       " 'atienza',\n",
       " 'atkin',\n",
       " 'atkinson',\n",
       " 'atl',\n",
       " 'atlant',\n",
       " 'atlanta',\n",
       " 'atlanti',\n",
       " 'atlas',\n",
       " 'atleast',\n",
       " 'atmospher',\n",
       " 'atom',\n",
       " 'aton',\n",
       " 'atop',\n",
       " 'atoradero',\n",
       " 'atrativo',\n",
       " 'atreo',\n",
       " 'atreus',\n",
       " 'att',\n",
       " 'attaboy',\n",
       " 'attach',\n",
       " 'attack',\n",
       " 'attain',\n",
       " 'attaint',\n",
       " 'attempt',\n",
       " 'attend',\n",
       " 'attent',\n",
       " 'atticus',\n",
       " 'attitud',\n",
       " 'attn',\n",
       " 'attorney',\n",
       " 'attract',\n",
       " 'attribut',\n",
       " 'atuchin',\n",
       " 'atv',\n",
       " 'atwel',\n",
       " 'atwood',\n",
       " 'atzichi',\n",
       " 'au',\n",
       " 'aubert',\n",
       " 'auburn',\n",
       " 'auckland',\n",
       " 'aucoin',\n",
       " 'auction',\n",
       " 'audi',\n",
       " 'audibl',\n",
       " 'audienc',\n",
       " 'audiencesport',\n",
       " 'audio',\n",
       " 'audioblock',\n",
       " 'audiobook',\n",
       " 'audioboom',\n",
       " 'audiojungl',\n",
       " 'audiomachin',\n",
       " 'audionautix',\n",
       " 'audionetwork',\n",
       " 'audit',\n",
       " 'auditorium',\n",
       " 'audrey',\n",
       " 'auf',\n",
       " 'aufiero',\n",
       " 'augment',\n",
       " 'august',\n",
       " 'augustus',\n",
       " 'aulani',\n",
       " 'aumentando',\n",
       " 'aundrea',\n",
       " 'aunt',\n",
       " ...]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aabi': 8.864419904994566,\n",
       " 'aafghani': 7.611656936499197,\n",
       " 'aaliyah': 7.94812917312041,\n",
       " 'aaliyahxo': 8.4589547968864,\n",
       " 'aam': 8.171272724434619,\n",
       " 'aaron': 6.33869126068631,\n",
       " 'ab': 7.611656936499197,\n",
       " 'abalo': 8.171272724434619,\n",
       " 'abandon': 6.667195327658346,\n",
       " 'abba': 8.4589547968864,\n",
       " 'abbey': 8.171272724434619,\n",
       " 'abbi': 7.94812917312041,\n",
       " 'abbrevi': 8.864419904994566,\n",
       " 'abc': 5.665746787443884,\n",
       " 'abcv': 7.94812917312041,\n",
       " 'abdallah': 8.864419904994566,\n",
       " 'abdelwahab': 7.94812917312041,\n",
       " 'abdom': 8.864419904994566,\n",
       " 'abdulla': 6.9926177280929736,\n",
       " 'abdullah': 7.94812917312041,\n",
       " 'abdulmateen': 8.4589547968864,\n",
       " 'abe': 8.864419904994566,\n",
       " 'abel': 6.9926177280929736,\n",
       " 'abelardo': 8.864419904994566,\n",
       " 'abenir': 8.864419904994566,\n",
       " 'abhijit': 8.4589547968864,\n",
       " 'abid': 8.4589547968864,\n",
       " 'abigail': 8.864419904994566,\n",
       " 'abil': 6.299470547533029,\n",
       " 'abl': 5.446693221381199,\n",
       " 'ablaz': 8.171272724434619,\n",
       " 'aboah': 8.864419904994566,\n",
       " 'aboard': 7.611656936499197,\n",
       " 'abonnez': 8.4589547968864,\n",
       " 'abort': 8.864419904994566,\n",
       " 'about': 5.1755404508806295,\n",
       " 'abov': 8.864419904994566,\n",
       " 'abovitz': 8.864419904994566,\n",
       " 'abqd': 8.4589547968864,\n",
       " 'abraham': 8.171272724434619,\n",
       " 'abram': 7.94812917312041,\n",
       " 'abroad': 7.07266043576651,\n",
       " 'abrupt': 8.171272724434619,\n",
       " 'abseil': 8.864419904994566,\n",
       " 'absent': 7.94812917312041,\n",
       " 'absolu': 8.864419904994566,\n",
       " 'absolut': 5.728925689065416,\n",
       " 'absorb': 8.171272724434619,\n",
       " 'abstract': 8.171272724434619,\n",
       " 'absurd': 7.94812917312041,\n",
       " 'abu': 7.765807616326455,\n",
       " 'abud': 8.864419904994566,\n",
       " 'abund': 7.94812917312041,\n",
       " 'abus': 7.07266043576651,\n",
       " 'abyss': 8.171272724434619,\n",
       " 'ac': 5.946649172910286,\n",
       " 'aca': 8.4589547968864,\n",
       " 'acaba': 8.864419904994566,\n",
       " 'acabado': 8.864419904994566,\n",
       " 'academ': 7.94812917312041,\n",
       " 'academi': 5.843995018850203,\n",
       " 'academia': 8.864419904994566,\n",
       " 'acanthus': 8.171272724434619,\n",
       " 'acc': 8.4589547968864,\n",
       " 'acceler': 8.864419904994566,\n",
       " 'accent': 7.360342508218292,\n",
       " 'accept': 5.665746787443884,\n",
       " 'access': 4.652292307116081,\n",
       " 'accessori': 6.6131281063880705,\n",
       " 'accid': 6.667195327658346,\n",
       " 'accident': 7.15967181275614,\n",
       " 'acclaim': 6.06105952408803,\n",
       " 'accommod': 7.765807616326455,\n",
       " 'accompani': 7.4781255438746745,\n",
       " 'accomplish': 7.94812917312041,\n",
       " 'accord': 6.299470547533029,\n",
       " 'account': 5.868687631440574,\n",
       " 'accumul': 7.611656936499197,\n",
       " 'accur': 7.94812917312041,\n",
       " 'accus': 6.724353741498295,\n",
       " 'ace': 7.15967181275614,\n",
       " 'acefamili': 8.4589547968864,\n",
       " 'acercado': 8.864419904994566,\n",
       " 'aceton': 8.864419904994566,\n",
       " 'ach': 8.864419904994566,\n",
       " 'achiev': 6.031206560938349,\n",
       " 'achok': 8.864419904994566,\n",
       " 'acid': 7.765807616326455,\n",
       " 'acima': 8.864419904994566,\n",
       " 'acknowledg': 8.864419904994566,\n",
       " 'acn': 7.94812917312041,\n",
       " 'aconteceu': 8.864419904994566,\n",
       " 'acoust': 6.918509755939252,\n",
       " 'acquaint': 6.422072869625361,\n",
       " 'acquir': 7.360342508218292,\n",
       " 'acr': 7.360342508218292,\n",
       " 'acreditado': 8.864419904994566,\n",
       " 'acrobat': 8.864419904994566,\n",
       " 'acromegali': 8.171272724434619,\n",
       " 'across': 4.546931791458254,\n",
       " 'acryl': 7.94812917312041,\n",
       " 'acsen': 8.4589547968864,\n",
       " 'act': 5.213761663700827,\n",
       " 'actinid': 8.864419904994566,\n",
       " 'action': 5.1387264777579125,\n",
       " 'activ': 6.466524632196195,\n",
       " 'activatemanag': 8.4589547968864,\n",
       " 'activist': 7.360342508218292,\n",
       " 'actor': 5.606323366973084,\n",
       " 'actress': 5.606323366973084,\n",
       " 'actual': 4.705536821634894,\n",
       " 'actuat': 8.864419904994566,\n",
       " 'acwel': 8.864419904994566,\n",
       " 'ad': 4.875435858430291,\n",
       " 'adair': 8.4589547968864,\n",
       " 'adam': 4.6597272856036,\n",
       " 'adamortiz': 8.864419904994566,\n",
       " 'adamruinseveryth': 8.4589547968864,\n",
       " 'adapt': 6.299470547533029,\n",
       " 'add': 5.398684002194839,\n",
       " 'addict': 7.4781255438746745,\n",
       " 'addison': 7.94812917312041,\n",
       " 'addit': 5.480029641648791,\n",
       " 'address': 5.398684002194839,\n",
       " 'adel': 8.171272724434619,\n",
       " 'adelaid': 8.171272724434619,\n",
       " 'adelain': 8.171272724434619,\n",
       " 'adelainemorin': 8.171272724434619,\n",
       " 'adelman': 8.864419904994566,\n",
       " 'aderinto': 8.4589547968864,\n",
       " 'adey': 8.864419904994566,\n",
       " 'adhes': 7.07266043576651,\n",
       " 'adi': 8.171272724434619,\n",
       " 'adick': 8.4589547968864,\n",
       " 'adida': 8.171272724434619,\n",
       " 'adil': 8.171272724434619,\n",
       " 'adjust': 7.4781255438746745,\n",
       " 'adler': 7.94812917312041,\n",
       " 'admet': 8.4589547968864,\n",
       " 'admin': 8.171272724434619,\n",
       " 'administ': 7.07266043576651,\n",
       " 'administr': 6.6131281063880705,\n",
       " 'admir': 7.765807616326455,\n",
       " 'admiss': 8.171272724434619,\n",
       " 'admit': 6.9926177280929736,\n",
       " 'admoni': 8.864419904994566,\n",
       " 'adnarimnavi': 8.4589547968864,\n",
       " 'ado': 8.864419904994566,\n",
       " 'adob': 6.190271255568037,\n",
       " 'adopt': 7.4781255438746745,\n",
       " 'ador': 6.561834812000519,\n",
       " 'adorn': 8.864419904994566,\n",
       " 'adria': 7.94812917312041,\n",
       " 'adriaensen': 8.4589547968864,\n",
       " 'adriana': 8.864419904994566,\n",
       " 'adriat': 8.171272724434619,\n",
       " 'adric': 8.171272724434619,\n",
       " 'adrien': 8.4589547968864,\n",
       " 'adrienelouis': 8.4589547968864,\n",
       " 'adrienn': 8.4589547968864,\n",
       " 'adrift': 8.864419904994566,\n",
       " 'adshead': 7.15967181275614,\n",
       " 'adult': 5.843995018850203,\n",
       " 'adulthood': 8.864419904994566,\n",
       " 'adultolesc': 8.171272724434619,\n",
       " 'adv': 8.171272724434619,\n",
       " 'advanc': 6.002219024065097,\n",
       " 'advantag': 7.4781255438746745,\n",
       " 'advent': 8.4589547968864,\n",
       " 'adventur': 4.375783535262426,\n",
       " 'adventuresom': 8.171272724434619,\n",
       " 'advert': 8.864419904994566,\n",
       " 'advertis': 6.784978363314729,\n",
       " 'advertori': 8.864419904994566,\n",
       " 'advic': 5.532215394819361,\n",
       " 'advis': 7.765807616326455,\n",
       " 'advisor': 8.4589547968864,\n",
       " 'advisori': 8.4589547968864,\n",
       " 'advoc': 7.94812917312041,\n",
       " 'advocaci': 7.765807616326455,\n",
       " 'adwoa': 8.864419904994566,\n",
       " 'adz': 8.4589547968864,\n",
       " 'aeri': 8.864419904994566,\n",
       " 'aerobat': 8.4589547968864,\n",
       " 'aerospac': 8.864419904994566,\n",
       " 'aesthet': 7.765807616326455,\n",
       " 'aeton': 7.15967181275614,\n",
       " 'af': 7.07266043576651,\n",
       " 'afa': 7.94812917312041,\n",
       " 'afanasjeva': 7.94812917312041,\n",
       " 'afantano': 8.864419904994566,\n",
       " 'afc': 7.611656936499197,\n",
       " 'affair': 6.724353741498295,\n",
       " 'affect': 6.561834812000519,\n",
       " 'affili': 4.392781111630997,\n",
       " 'affirm': 7.94812917312041,\n",
       " 'affleck': 6.379513255206565,\n",
       " 'afford': 6.261730219550182,\n",
       " 'afi': 7.94812917312041,\n",
       " 'afici': 8.864419904994566,\n",
       " 'aficionado': 8.864419904994566,\n",
       " 'afoot': 8.864419904994566,\n",
       " 'afp': 8.864419904994566,\n",
       " 'afraid': 6.724353741498295,\n",
       " 'africa': 7.360342508218292,\n",
       " 'african': 7.15967181275614,\n",
       " 'afriqu': 8.864419904994566,\n",
       " 'afrojack': 7.765807616326455,\n",
       " 'after': 4.93259427227024,\n",
       " 'afterglow': 8.864419904994566,\n",
       " 'aftermath': 7.15967181275614,\n",
       " 'afternoon': 6.9926177280929736,\n",
       " 'aftershav': 8.864419904994566,\n",
       " 'aftershow': 7.94812917312041,\n",
       " 'afterward': 8.4589547968864,\n",
       " 'aftra': 8.4589547968864,\n",
       " 'ag': 8.864419904994566,\n",
       " 'again': 6.724353741498295,\n",
       " 'agdao': 8.864419904994566,\n",
       " 'age': 5.430432700509419,\n",
       " 'ageless': 8.864419904994566,\n",
       " 'agenc': 6.918509755939252,\n",
       " 'agenda': 7.611656936499197,\n",
       " 'agent': 6.8495168844523,\n",
       " 'aggreg': 7.4781255438746745,\n",
       " 'aggress': 7.15967181275614,\n",
       " 'agich': 7.611656936499197,\n",
       " 'agier': 8.4589547968864,\n",
       " 'agil': 8.864419904994566,\n",
       " 'agl': 8.864419904994566,\n",
       " 'agnolotti': 8.4589547968864,\n",
       " 'ago': 5.707419483844452,\n",
       " 'agoodnight': 8.864419904994566,\n",
       " 'agora': 7.94812917312041,\n",
       " 'agre': 6.724353741498295,\n",
       " 'agreement': 7.254981992560465,\n",
       " 'agress': 8.864419904994566,\n",
       " 'agro': 8.864419904994566,\n",
       " 'agua': 8.864419904994566,\n",
       " 'aguilar': 8.864419904994566,\n",
       " 'aguilera': 7.611656936499197,\n",
       " 'aguirr': 8.4589547968864,\n",
       " 'ah': 8.171272724434619,\n",
       " 'ahead': 5.568583038990236,\n",
       " 'ahh': 8.171272724434619,\n",
       " 'ahhh': 8.4589547968864,\n",
       " 'ahmad': 7.611656936499197,\n",
       " 'ahora': 8.4589547968864,\n",
       " 'ahuja': 8.171272724434619,\n",
       " 'ai': 7.94812917312041,\n",
       " 'aid': 6.33869126068631,\n",
       " 'aidan': 8.4589547968864,\n",
       " 'aidi': 8.171272724434619,\n",
       " 'aiea': 8.171272724434619,\n",
       " 'aif': 8.864419904994566,\n",
       " 'aih': 8.4589547968864,\n",
       " 'aiken': 8.864419904994566,\n",
       " 'aikin': 8.864419904994566,\n",
       " 'aiko': 8.864419904994566,\n",
       " 'ailment': 8.864419904994566,\n",
       " 'aim': 6.9926177280929736,\n",
       " 'aiman': 8.4589547968864,\n",
       " 'aimez': 8.4589547968864,\n",
       " 'ain': 8.4589547968864,\n",
       " 'aina': 7.254981992560465,\n",
       " 'ainsley': 8.864419904994566,\n",
       " 'aint': 7.94812917312041,\n",
       " 'air': 4.821368637160015,\n",
       " 'airbnb': 8.4589547968864,\n",
       " 'airbrush': 7.765807616326455,\n",
       " 'airbus': 8.864419904994566,\n",
       " 'aircraft': 7.360342508218292,\n",
       " 'airi': 8.4589547968864,\n",
       " 'airlift': 8.864419904994566,\n",
       " 'airlin': 7.254981992560465,\n",
       " 'airman': 8.171272724434619,\n",
       " 'airplan': 6.8495168844523,\n",
       " 'airpod': 7.611656936499197,\n",
       " 'airport': 7.4781255438746745,\n",
       " 'airspun': 7.94812917312041,\n",
       " 'airtight': 8.171272724434619,\n",
       " 'airwav': 8.171272724434619,\n",
       " 'ais': 8.171272724434619,\n",
       " 'aisha': 7.765807616326455,\n",
       " 'aisl': 8.171272724434619,\n",
       " 'aispuro': 7.765807616326455,\n",
       " 'aitan': 8.171272724434619,\n",
       " 'aitchison': 8.4589547968864,\n",
       " 'aiy': 8.864419904994566,\n",
       " 'aj': 7.360342508218292,\n",
       " 'aja': 8.864419904994566,\n",
       " 'ajax': 8.4589547968864,\n",
       " 'ajay': 8.4589547968864,\n",
       " 'ajinkya': 8.4589547968864,\n",
       " 'ajiri': 7.765807616326455,\n",
       " 'ajit': 8.864419904994566,\n",
       " 'ajn': 8.864419904994566,\n",
       " 'ak': 7.4781255438746745,\n",
       " 'aka': 6.031206560938349,\n",
       " 'akademik': 8.864419904994566,\n",
       " 'akana': 8.4589547968864,\n",
       " 'akerman': 8.171272724434619,\n",
       " 'akin': 8.4589547968864,\n",
       " 'akira': 8.864419904994566,\n",
       " 'akkai': 8.864419904994566,\n",
       " 'akpanudosen': 8.864419904994566,\n",
       " 'akpolo': 7.765807616326455,\n",
       " 'akubez': 8.4589547968864,\n",
       " 'al': 6.379513255206565,\n",
       " 'ala': 8.4589547968864,\n",
       " 'alabama': 7.611656936499197,\n",
       " 'alabamian': 8.4589547968864,\n",
       " 'alabast': 8.864419904994566,\n",
       " 'alan': 5.974048147098401,\n",
       " 'alana': 8.864419904994566,\n",
       " 'alarcon': 7.94812917312041,\n",
       " 'alarm': 8.4589547968864,\n",
       " 'alasdair': 8.171272724434619,\n",
       " 'alasiri': 8.864419904994566,\n",
       " 'alaska': 7.611656936499197,\n",
       " 'alastair': 7.94812917312041,\n",
       " 'alba': 8.864419904994566,\n",
       " 'albani': 8.4589547968864,\n",
       " 'albatross': 8.4589547968864,\n",
       " 'alberini': 8.4589547968864,\n",
       " 'albert': 7.765807616326455,\n",
       " 'alberto': 7.765807616326455,\n",
       " 'albrecht': 7.254981992560465,\n",
       " 'album': 3.8177741733752764,\n",
       " 'albuquerqu': 7.4781255438746745,\n",
       " 'alcantara': 8.864419904994566,\n",
       " 'alcohol': 7.254981992560465,\n",
       " 'alcuni': 8.864419904994566,\n",
       " 'alda': 8.864419904994566,\n",
       " 'aldavaz': 8.864419904994566,\n",
       " 'aldo': 7.765807616326455,\n",
       " 'aldridg': 8.171272724434619,\n",
       " 'ale': 8.171272724434619,\n",
       " 'alec': 7.15967181275614,\n",
       " 'alecsteel': 8.864419904994566,\n",
       " 'alegria': 8.864419904994566,\n",
       " 'alejandro': 7.94812917312041,\n",
       " 'alek': 8.864419904994566,\n",
       " 'aleksandar': 7.94812917312041,\n",
       " 'alert': 6.724353741498295,\n",
       " 'alessandra': 7.611656936499197,\n",
       " 'alessandralorenn': 8.864419904994566,\n",
       " 'alessandro': 7.94812917312041,\n",
       " 'alessia': 7.254981992560465,\n",
       " 'alesso': 7.94812917312041,\n",
       " 'alex': 5.014272303284507,\n",
       " 'alexa': 6.918509755939252,\n",
       " 'alexand': 5.843995018850203,\n",
       " 'alexandr': 8.864419904994566,\n",
       " 'alexandra': 6.918509755939252,\n",
       " 'alexandrina': 8.4589547968864,\n",
       " 'alexandru': 8.4589547968864,\n",
       " 'alexi': 6.6131281063880705,\n",
       " 'alexjon': 8.864419904994566,\n",
       " 'alfa': 7.765807616326455,\n",
       " 'alfr': 7.765807616326455,\n",
       " 'alga': 8.864419904994566,\n",
       " 'algebra': 8.4589547968864,\n",
       " 'alghamdi': 6.8495168844523,\n",
       " 'algonquin': 8.4589547968864,\n",
       " 'algorithm': 6.9926177280929736,\n",
       " 'algun': 8.864419904994566,\n",
       " 'alhambra': 8.171272724434619,\n",
       " 'alhazzaa': 8.4589547968864,\n",
       " 'alhulail': 8.171272724434619,\n",
       " 'ali': 6.6131281063880705,\n",
       " 'alibaba': 8.864419904994566,\n",
       " 'alic': 6.784978363314729,\n",
       " 'alicia': 7.07266043576651,\n",
       " 'alien': 6.667195327658346,\n",
       " 'alienist': 7.94812917312041,\n",
       " 'align': 7.94812917312041,\n",
       " 'alik': 7.15967181275614,\n",
       " 'alile': 8.864419904994566,\n",
       " 'alina': 8.171272724434619,\n",
       " 'aliouch': 8.4589547968864,\n",
       " 'alisha': 7.611656936499197,\n",
       " 'alishamari': 7.611656936499197,\n",
       " 'alison': 7.94812917312041,\n",
       " 'alissa': 7.765807616326455,\n",
       " 'alita': 8.171272724434619,\n",
       " 'aliv': 6.2253625753793065,\n",
       " 'aliyya': 8.864419904994566,\n",
       " 'aliza': 8.4589547968864,\n",
       " 'aljagbir': 8.4589547968864,\n",
       " 'alkali': 8.864419904994566,\n",
       " 'alkhatib': 8.4589547968864,\n",
       " 'alkhulaifi': 8.171272724434619,\n",
       " 'all': 3.6522052374999405,\n",
       " 'allan': 8.4589547968864,\n",
       " 'allana': 8.4589547968864,\n",
       " 'alleg': 6.422072869625361,\n",
       " 'allegan': 7.4781255438746745,\n",
       " 'allegi': 8.864419904994566,\n",
       " 'allegr': 8.171272724434619,\n",
       " 'allegro': 7.94812917312041,\n",
       " 'allen': 6.091831182754784,\n",
       " 'allerg': 7.765807616326455,\n",
       " 'alley': 8.171272724434619,\n",
       " 'allfallsdown': 8.864419904994566,\n",
       " 'alli': 6.299470547533029,\n",
       " 'allianc': 8.4589547968864,\n",
       " 'allianz': 8.171272724434619,\n",
       " 'alliegbeauti': 8.864419904994566,\n",
       " 'alliegpalett': 8.864419904994566,\n",
       " 'allig': 8.4589547968864,\n",
       " 'allison': 7.360342508218292,\n",
       " 'alloutwar': 7.94812917312041,\n",
       " 'allow': 5.5145158177199605,\n",
       " 'allrecip': 7.4781255438746745,\n",
       " 'allstar': 8.171272724434619,\n",
       " 'allthat': 8.864419904994566,\n",
       " 'alltta': 6.8495168844523,\n",
       " 'allur': 7.765807616326455,\n",
       " 'allysa': 8.864419904994566,\n",
       " 'alma': 8.864419904994566,\n",
       " 'almagu': 7.765807616326455,\n",
       " 'almanac': 7.765807616326455,\n",
       " 'almazankitchen': 8.864419904994566,\n",
       " 'almeda': 8.864419904994566,\n",
       " 'almellehan': 8.864419904994566,\n",
       " 'almond': 6.724353741498295,\n",
       " 'almost': 5.707419483844452,\n",
       " 'alo': 8.4589547968864,\n",
       " 'alon': 5.383179815658874,\n",
       " 'along': 4.546931791458254,\n",
       " 'alongsid': 6.784978363314729,\n",
       " 'alot': 8.171272724434619,\n",
       " 'alpert': 8.171272724434619,\n",
       " 'alpha': 7.15967181275614,\n",
       " 'alphacat': 8.864419904994566,\n",
       " 'alpin': 8.4589547968864,\n",
       " 'alrdridg': 8.4589547968864,\n",
       " 'alreadi': 5.55023390032204,\n",
       " 'alright': 6.9926177280929736,\n",
       " 'alsemgeest': 8.864419904994566,\n",
       " 'also': 3.6440640799162405,\n",
       " 'alsop': 8.864419904994566,\n",
       " 'alt': 7.765807616326455,\n",
       " 'alter': 7.360342508218292,\n",
       " 'altern': 6.06105952408803,\n",
       " 'although': 6.918509755939252,\n",
       " 'altitud': 8.864419904994566,\n",
       " 'altman': 8.864419904994566,\n",
       " 'alto': 7.4781255438746745,\n",
       " 'altogeth': 8.171272724434619,\n",
       " 'altonaga': 8.864419904994566,\n",
       " 'altraid': 8.864419904994566,\n",
       " 'altuwaijri': 7.94812917312041,\n",
       " 'alucia': 8.4589547968864,\n",
       " 'alum': 8.171272724434619,\n",
       " 'aluminium': 8.4589547968864,\n",
       " 'aluminum': 7.360342508218292,\n",
       " 'alv': 6.8495168844523,\n",
       " 'alvarado': 8.171272724434619,\n",
       " 'alvarez': 8.171272724434619,\n",
       " 'alvaro': 8.864419904994566,\n",
       " 'alveoli': 8.864419904994566,\n",
       " 'alverez': 8.864419904994566,\n",
       " 'alvey': 8.4589547968864,\n",
       " 'alvin': 6.8495168844523,\n",
       " 'alvinnn': 8.864419904994566,\n",
       " 'alvord': 8.171272724434619,\n",
       " 'alway': 4.186929057426848,\n",
       " 'alwin': 8.171272724434619,\n",
       " 'alyssa': 6.918509755939252,\n",
       " 'am': 5.946649172910286,\n",
       " 'ama': 6.918509755939252,\n",
       " 'amadeus': 8.864419904994566,\n",
       " 'amahl': 8.864419904994566,\n",
       " 'amanda': 6.6131281063880705,\n",
       " 'amangiri': 8.171272724434619,\n",
       " 'amant': 8.864419904994566,\n",
       " 'amapola': 7.94812917312041,\n",
       " 'amara': 8.171272724434619,\n",
       " 'amaranth': 8.864419904994566,\n",
       " 'amari': 7.94812917312041,\n",
       " 'amarillo': 8.4589547968864,\n",
       " 'amarxistphil': 8.4589547968864,\n",
       " 'amateur': 8.4589547968864,\n",
       " 'amaz': 4.305293657507881,\n",
       " 'amazebal': 8.4589547968864,\n",
       " 'amazon': 4.830179266842171,\n",
       " 'amazonian': 8.864419904994566,\n",
       " 'ambassador': 7.07266043576651,\n",
       " 'amber': 6.8495168844523,\n",
       " 'amberschol': 7.15967181275614,\n",
       " 'ambient': 7.611656936499197,\n",
       " 'ambit': 7.360342508218292,\n",
       " 'ambiti': 7.254981992560465,\n",
       " 'ambl': 8.864419904994566,\n",
       " 'amblin': 7.611656936499197,\n",
       " 'ambul': 8.4589547968864,\n",
       " 'ambush': 8.4589547968864,\n",
       " 'amc': 7.254981992560465,\n",
       " 'ameen': 8.4589547968864,\n",
       " 'amel': 7.94812917312041,\n",
       " 'amelia': 8.171272724434619,\n",
       " 'amelior': 8.864419904994566,\n",
       " 'amen': 8.4589547968864,\n",
       " 'amend': 8.4589547968864,\n",
       " 'amendolar': 8.4589547968864,\n",
       " 'america': 4.922838097324875,\n",
       " 'american': 4.875435858430291,\n",
       " 'americana': 8.4589547968864,\n",
       " 'americatvletsplay': 8.171272724434619,\n",
       " 'amg': 8.864419904994566,\n",
       " 'ami': 5.5145158177199605,\n",
       " 'amick': 7.765807616326455,\n",
       " 'amico': 8.864419904994566,\n",
       " 'amid': 7.611656936499197,\n",
       " 'amiibo': 8.4589547968864,\n",
       " 'amir': 8.4589547968864,\n",
       " 'amityvill': 8.4589547968864,\n",
       " 'aml': 8.864419904994566,\n",
       " 'ammar': 7.765807616326455,\n",
       " 'amnesia': 6.918509755939252,\n",
       " 'amo': 8.171272724434619,\n",
       " 'amol': 8.171272724434619,\n",
       " 'among': 7.07266043576651,\n",
       " 'amongst': 7.15967181275614,\n",
       " 'amor': 8.864419904994566,\n",
       " 'amount': 6.8495168844523,\n",
       " 'amp': 6.667195327658346,\n",
       " 'amphibian': 8.864419904994566,\n",
       " 'amphitheat': 6.9926177280929736,\n",
       " 'amphitheatr': 7.15967181275614,\n",
       " 'ampitheatr': 7.4781255438746745,\n",
       " 'amritsar': 8.171272724434619,\n",
       " 'amrul': 8.171272724434619,\n",
       " 'amsterdam': 7.360342508218292,\n",
       " 'amtrak': 7.07266043576651,\n",
       " 'amuka': 8.4589547968864,\n",
       " 'amus': 8.864419904994566,\n",
       " 'an': 5.1387264777579125,\n",
       " 'ana': 7.4781255438746745,\n",
       " 'anacita': 8.864419904994566,\n",
       " 'anaheim': 7.360342508218292,\n",
       " 'anai': 7.611656936499197,\n",
       " 'anakin': 8.171272724434619,\n",
       " 'analog': 7.15967181275614,\n",
       " 'analogu': 8.864419904994566,\n",
       " 'analys': 8.864419904994566,\n",
       " 'analysi': 6.156369703892356,\n",
       " 'analyt': 8.864419904994566,\n",
       " 'analytica': 8.864419904994566,\n",
       " 'analyz': 8.4589547968864,\n",
       " 'anand': 8.171272724434619,\n",
       " 'anarchi': 8.171272724434619,\n",
       " 'anastasia': 7.07266043576651,\n",
       " 'anatom': 8.4589547968864,\n",
       " 'anatomi': 8.171272724434619,\n",
       " 'ancestor': 8.864419904994566,\n",
       " 'ancestri': 8.4589547968864,\n",
       " 'anchor': 7.15967181275614,\n",
       " 'ancient': 6.466524632196195,\n",
       " 'and': 3.933549579367172,\n",
       " 'andant': 8.171272724434619,\n",
       " 'andaya': 8.4589547968864,\n",
       " 'andddd': 8.864419904994566,\n",
       " 'ander': 8.171272724434619,\n",
       " 'andersen': 7.4781255438746745,\n",
       " 'anderson': 5.430432700509419,\n",
       " 'andersson': 6.918509755939252,\n",
       " 'andi': 5.294887208513195,\n",
       " 'andor': 7.94812917312041,\n",
       " 'andow': 8.864419904994566,\n",
       " 'andr': 6.2253625753793065,\n",
       " 'andra': 8.864419904994566,\n",
       " 'andrea': 6.466524632196195,\n",
       " 'andreassen': 7.765807616326455,\n",
       " 'andrei': 7.611656936499197,\n",
       " 'andrej': 8.864419904994566,\n",
       " 'andrethegi': 8.171272724434619,\n",
       " 'andrew': 4.866219203325366,\n",
       " 'andrewdeast': 8.864419904994566,\n",
       " 'andrewstwitt': 8.864419904994566,\n",
       " 'andrewturnsdown': 8.171272724434619,\n",
       " 'andrey': 7.611656936499197,\n",
       " 'android': 5.532215394819361,\n",
       " 'anecdot': 8.864419904994566,\n",
       " 'aneurysm': 8.4589547968864,\n",
       " 'ang': 8.171272724434619,\n",
       " 'angel': 4.729253348252209,\n",
       " 'angela': 7.765807616326455,\n",
       " 'angelea': 8.864419904994566,\n",
       " 'angelina': 7.94812917312041,\n",
       " 'anger': 7.254981992560465,\n",
       " 'angi': 6.9926177280929736,\n",
       " 'angl': 6.091831182754784,\n",
       " 'anglerfish': 8.171272724434619,\n",
       " 'angri': 8.171272724434619,\n",
       " 'angrybirdsmatch': 8.4589547968864,\n",
       " 'anh': 7.94812917312041,\n",
       " 'ani': 6.379513255206565,\n",
       " 'anika': 8.171272724434619,\n",
       " 'anim': 3.90507790528586,\n",
       " 'animatron': 7.94812917312041,\n",
       " 'animoji': 8.4589547968864,\n",
       " 'aniston': 6.561834812000519,\n",
       " 'anitta': 7.94812917312041,\n",
       " 'anker': 8.864419904994566,\n",
       " 'ankl': 8.171272724434619,\n",
       " 'ann': 6.422072869625361,\n",
       " 'anna': 6.561834812000519,\n",
       " 'annaakana': 8.4589547968864,\n",
       " 'annabell': 7.765807616326455,\n",
       " 'annalora': 8.864419904994566,\n",
       " 'annalynn': 8.864419904994566,\n",
       " 'annamaria': 8.4589547968864,\n",
       " 'annapurna': 7.94812917312041,\n",
       " 'annasophia': 8.864419904994566,\n",
       " 'annemari': 8.864419904994566,\n",
       " 'annemariemus': 8.864419904994566,\n",
       " 'annett': 7.254981992560465,\n",
       " 'anni': 8.4589547968864,\n",
       " 'annihil': 7.4781255438746745,\n",
       " 'anniversari': 7.254981992560465,\n",
       " 'annouc': 8.864419904994566,\n",
       " 'announc': 5.480029641648791,\n",
       " 'annoy': 7.611656936499197,\n",
       " 'annual': 5.946649172910286,\n",
       " 'annuar': 8.4589547968864,\n",
       " 'anolini': 8.4589547968864,\n",
       " 'anonym': 6.724353741498295,\n",
       " 'anoplolepi': 8.864419904994566,\n",
       " 'anoth': 4.93259427227024,\n",
       " 'ansel': 8.864419904994566,\n",
       " 'anson': 7.254981992560465,\n",
       " 'answer': 4.821368637160015,\n",
       " 'ant': 7.15967181275614,\n",
       " 'antarct': 8.4589547968864,\n",
       " 'antarctica': 8.4589547968864,\n",
       " 'antetokounmpo': 8.864419904994566,\n",
       " 'anthem': 6.33869126068631,\n",
       " 'antholog': 8.864419904994566,\n",
       " 'anthoni': 5.750904595784191,\n",
       " 'anthonygargiula': 8.171272724434619,\n",
       " 'anthropocen': 8.864419904994566,\n",
       " 'anthropolog': 8.4589547968864,\n",
       " 'anti': 6.9926177280929736,\n",
       " 'antibiot': 7.94812917312041,\n",
       " 'antibodi': 8.864419904994566,\n",
       " 'antic': 7.611656936499197,\n",
       " 'anticip': 6.513044647831087,\n",
       " 'antidot': 8.4589547968864,\n",
       " 'antigen': 8.864419904994566,\n",
       " 'antimoni': 8.864419904994566,\n",
       " 'antiqu': 8.171272724434619,\n",
       " 'antoin': 8.171272724434619,\n",
       " 'anton': 7.765807616326455,\n",
       " 'antoni': 7.360342508218292,\n",
       " 'antonio': 6.724353741498295,\n",
       " 'antonyan': 8.4589547968864,\n",
       " 'antscanada': 8.864419904994566,\n",
       " 'antwerp': 8.171272724434619,\n",
       " 'anuj': 8.4589547968864,\n",
       " 'anuka': 8.864419904994566,\n",
       " 'anwar': 7.94812917312041,\n",
       " 'anxieti': 6.918509755939252,\n",
       " 'anxious': 7.07266043576651,\n",
       " 'anya': 8.864419904994566,\n",
       " 'anybodi': 8.864419904994566,\n",
       " 'anymor': 6.561834812000519,\n",
       " 'anyon': 5.625741452830185,\n",
       " 'anyth': 4.93259427227024,\n",
       " 'anytim': 5.03577850850547,\n",
       " 'anyway': 7.4781255438746745,\n",
       " 'anywher': 4.922838097324875,\n",
       " 'anz': 7.611656936499197,\n",
       " 'anzivino': 7.94812917312041,\n",
       " 'ao': 8.864419904994566,\n",
       " 'aoi': 8.864419904994566,\n",
       " 'aoki': 8.171272724434619,\n",
       " 'ap': 6.784978363314729,\n",
       " 'apa': 7.611656936499197,\n",
       " 'aparec': 8.864419904994566,\n",
       " 'aparent': 8.4589547968864,\n",
       " 'apart': 5.707419483844452,\n",
       " 'apasionado': 8.864419904994566,\n",
       " 'apathi': 8.4589547968864,\n",
       " 'ape': 6.784978363314729,\n",
       " 'apertur': 7.4781255438746745,\n",
       " 'apesar': 8.864419904994566,\n",
       " 'apm': 8.171272724434619,\n",
       " 'apocalyps': 7.07266043576651,\n",
       " 'apoge': 8.864419904994566,\n",
       " 'apollo': 7.4781255438746745,\n",
       " 'apolog': 6.466524632196195,\n",
       " 'apologis': 7.611656936499197,\n",
       " 'app': 4.150395314094392,\n",
       " 'appar': 7.254981992560465,\n",
       " 'apparel': 6.784978363314729,\n",
       " 'appeal': 7.254981992560465,\n",
       " 'appear': 5.446693221381199,\n",
       " 'appeas': 8.864419904994566,\n",
       " 'appendix': 8.4589547968864,\n",
       " 'appetit': 6.06105952408803,\n",
       " 'appl': 4.866219203325366,\n",
       " 'applaud': 8.864419904994566,\n",
       " 'applaus': 7.94812917312041,\n",
       " 'applemus': 8.864419904994566,\n",
       " 'applepi': 7.611656936499197,\n",
       " 'applese': 8.864419904994566,\n",
       " 'appli': 6.299470547533029,\n",
       " 'applic': 6.784978363314729,\n",
       " 'appoint': 8.4589547968864,\n",
       " 'appreci': 5.974048147098401,\n",
       " 'apprentic': 7.94812917312041,\n",
       " 'approach': 6.33869126068631,\n",
       " 'appropri': 7.94812917312041,\n",
       " 'approv': 7.15967181275614,\n",
       " 'approxim': 6.422072869625361,\n",
       " 'apr': 8.4589547968864,\n",
       " 'apricot': 8.864419904994566,\n",
       " 'april': 5.323460580957251,\n",
       " 'apron': 6.918509755939252,\n",
       " 'apt': 8.864419904994566,\n",
       " 'aptak': 8.171272724434619,\n",
       " 'aptitud': 8.864419904994566,\n",
       " 'apyrodesign': 7.94812917312041,\n",
       " 'aqeel': 8.864419904994566,\n",
       " 'aqu': 8.171272724434619,\n",
       " 'aqua': 7.07266043576651,\n",
       " 'aquaman': 8.171272724434619,\n",
       " 'aquarium': 8.4589547968864,\n",
       " 'aquascap': 8.864419904994566,\n",
       " 'aqui': 8.864419904994566,\n",
       " 'aquietplac': 8.171272724434619,\n",
       " 'aquilina': 7.94812917312041,\n",
       " 'ar': 6.724353741498295,\n",
       " 'ara': 8.171272724434619,\n",
       " 'arab': 8.171272724434619,\n",
       " 'aragon': 8.864419904994566,\n",
       " 'aranda': 8.171272724434619,\n",
       " 'arashiyama': 7.94812917312041,\n",
       " 'arbitr': 8.4589547968864,\n",
       " 'arboretum': 8.171272724434619,\n",
       " 'arbuckl': 8.4589547968864,\n",
       " 'arc': 8.864419904994566,\n",
       " 'arcad': 7.07266043576651,\n",
       " 'arcaini': 8.864419904994566,\n",
       " 'arcainiiii': 8.864419904994566,\n",
       " 'arch': 7.94812917312041,\n",
       " 'archaeologist': 8.4589547968864,\n",
       " 'archeologico': 8.864419904994566,\n",
       " 'archer': 8.171272724434619,\n",
       " 'archi': 7.4781255438746745,\n",
       " 'archibishop': 8.171272724434619,\n",
       " 'architectur': 7.360342508218292,\n",
       " 'archiv': 6.33869126068631,\n",
       " 'archivist': 8.864419904994566,\n",
       " 'archuleta': 8.171272724434619,\n",
       " 'arctic': 7.360342508218292,\n",
       " 'arden': 7.94812917312041,\n",
       " 'arduino': 8.171272724434619,\n",
       " 'are': 5.383179815658874,\n",
       " 'area': 6.466524632196195,\n",
       " 'arena': 6.9926177280929736,\n",
       " 'arevalo': 8.4589547968864,\n",
       " 'areyouwithus': 8.864419904994566,\n",
       " 'argentin': 8.171272724434619,\n",
       " 'argentina': 7.611656936499197,\n",
       " 'argon': 8.864419904994566,\n",
       " 'argu': 7.765807616326455,\n",
       " 'arguabl': 8.864419904994566,\n",
       " 'arguell': 7.94812917312041,\n",
       " 'argument': 7.611656936499197,\n",
       " 'ari': 7.4781255438746745,\n",
       " 'aria': 8.4589547968864,\n",
       " 'ariana': 8.4589547968864,\n",
       " 'ariel': 7.611656936499197,\n",
       " 'ariell': 8.864419904994566,\n",
       " 'arikare': 8.864419904994566,\n",
       " 'arikareean': 8.864419904994566,\n",
       " 'arisa': 8.171272724434619,\n",
       " 'aristocraci': 8.864419904994566,\n",
       " 'aristocrat': 8.864419904994566,\n",
       " 'aritaum': 8.864419904994566,\n",
       " 'ariza': 8.4589547968864,\n",
       " 'arizona': 7.360342508218292,\n",
       " 'arjen': 8.4589547968864,\n",
       " 'arjona': 7.94812917312041,\n",
       " 'ark': 7.611656936499197,\n",
       " 'arkadiy': 6.918509755939252,\n",
       " 'arkansa': 8.864419904994566,\n",
       " 'arlook': 8.864419904994566,\n",
       " 'arm': 6.156369703892356,\n",
       " 'armando': 7.94812917312041,\n",
       " 'armani': 7.611656936499197,\n",
       " 'armengol': 8.864419904994566,\n",
       " 'armi': 6.466524632196195,\n",
       " 'armisen': 8.171272724434619,\n",
       " 'armori': 8.4589547968864,\n",
       " 'armpit': 8.864419904994566,\n",
       " 'armstrong': 7.254981992560465,\n",
       " 'arnaud': 8.4589547968864,\n",
       " 'arnold': 7.4781255438746745,\n",
       " 'arntzen': 8.864419904994566,\n",
       " 'aronian': 8.864419904994566,\n",
       " 'around': 4.163939539202149,\n",
       " 'arpaio': 8.864419904994566,\n",
       " 'arpel': 8.864419904994566,\n",
       " 'arpita': 7.94812917312041,\n",
       " 'arr': 8.4589547968864,\n",
       " 'arra': 8.864419904994566,\n",
       " 'arraign': 8.864419904994566,\n",
       " 'arrancado': 8.864419904994566,\n",
       " 'arrang': 6.667195327658346,\n",
       " 'array': 7.94812917312041,\n",
       " 'arrest': 7.94812917312041,\n",
       " 'arri': 8.864419904994566,\n",
       " 'arriba': 8.864419904994566,\n",
       " 'arriola': 8.4589547968864,\n",
       " 'arriv': 5.625741452830185,\n",
       " 'arriveth': 8.864419904994566,\n",
       " 'arrog': 8.4589547968864,\n",
       " 'arrow': 6.667195327658346,\n",
       " 'arsenal': 8.864419904994566,\n",
       " 'arsenic': 8.864419904994566,\n",
       " 'arslan': 8.4589547968864,\n",
       " 'art': 4.770075342772465,\n",
       " 'artbeatz': 8.4589547968864,\n",
       " 'artemi': 8.4589547968864,\n",
       " 'arthur': 7.4781255438746745,\n",
       " 'articl': 5.773377451636249,\n",
       " 'artifact': 7.765807616326455,\n",
       " 'artifici': 7.765807616326455,\n",
       " 'artisan': 8.4589547968864,\n",
       " 'artist': 4.753546040821254,\n",
       " 'artista': 8.864419904994566,\n",
       " 'artisthowel': 8.4589547968864,\n",
       " 'artistool': 8.864419904994566,\n",
       " 'artistri': 8.171272724434619,\n",
       " 'artlist': 8.171272724434619,\n",
       " 'artpark': 8.4589547968864,\n",
       " 'artwork': 7.15967181275614,\n",
       " 'arun': 8.864419904994566,\n",
       " 'arunabh': 8.171272724434619,\n",
       " 'arviso': 7.07266043576651,\n",
       " 'as': 4.962447235419921,\n",
       " 'asap': 8.4589547968864,\n",
       " 'asapsci': 7.765807616326455,\n",
       " 'asar': 8.4589547968864,\n",
       " 'asburi': 7.94812917312041,\n",
       " 'asc': 8.4589547968864,\n",
       " 'ascap': 6.918509755939252,\n",
       " 'ascenso': 8.864419904994566,\n",
       " 'ascot': 8.864419904994566,\n",
       " 'asean': 8.864419904994566,\n",
       " 'ash': 6.299470547533029,\n",
       " 'asham': 7.4781255438746745,\n",
       " 'ashanti': 8.864419904994566,\n",
       " 'asher': 8.864419904994566,\n",
       " 'ashevill': 8.4589547968864,\n",
       " 'ashland': 8.864419904994566,\n",
       " 'ashleigh': 7.765807616326455,\n",
       " 'ashley': 6.190271255568037,\n",
       " 'ashleyi': 7.765807616326455,\n",
       " 'ashmor': 6.8495168844523,\n",
       " 'ashton': 8.864419904994566,\n",
       " 'ashtray': 8.171272724434619,\n",
       " 'asia': 6.261730219550182,\n",
       " 'asian': 7.4781255438746745,\n",
       " 'asianaesingstooyouu': 8.4589547968864,\n",
       " 'asifitsyourlast': 8.864419904994566,\n",
       " 'asiryan': 7.94812917312041,\n",
       " 'ask': 4.5402872487395864,\n",
       " 'askew': 8.4589547968864,\n",
       " 'askhermor': 8.864419904994566,\n",
       " 'aslan': 8.864419904994566,\n",
       " 'asleep': 8.171272724434619,\n",
       " 'asmr': 6.9926177280929736,\n",
       " 'asmrdarl': 8.864419904994566,\n",
       " 'aso': 7.765807616326455,\n",
       " 'aspect': 7.07266043576651,\n",
       " 'aspen': 8.4589547968864,\n",
       " 'asphalt': 8.4589547968864,\n",
       " 'aspic': 8.864419904994566,\n",
       " 'aspir': 7.360342508218292,\n",
       " 'asprir': 8.4589547968864,\n",
       " 'ass': 7.611656936499197,\n",
       " 'assaf': 8.864419904994566,\n",
       " 'assassin': 6.8495168844523,\n",
       " 'assault': 6.784978363314729,\n",
       " 'assembl': 7.254981992560465,\n",
       " 'assent': 8.864419904994566,\n",
       " 'assert': 8.864419904994566,\n",
       " 'assess': 8.4589547968864,\n",
       " 'asset': 8.864419904994566,\n",
       " 'asshol': 8.864419904994566,\n",
       " 'assi': 8.864419904994566,\n",
       " 'assign': 8.171272724434619,\n",
       " 'assim': 8.864419904994566,\n",
       " 'assist': 4.6900326350989285,\n",
       " 'associ': 5.367912343528085,\n",
       " 'assum': 5.796366969860948,\n",
       " 'assumpt': 7.94812917312041,\n",
       " 'assur': 7.765807616326455,\n",
       " 'astatin': 8.864419904994566,\n",
       " 'aster': 8.4589547968864,\n",
       " 'asterisk': 8.4589547968864,\n",
       " 'asteroid': 7.611656936499197,\n",
       " 'asthma': 8.864419904994566,\n",
       " 'astia': 7.765807616326455,\n",
       " 'aston': 8.171272724434619,\n",
       " 'astonish': 7.765807616326455,\n",
       " 'astori': 8.4589547968864,\n",
       " 'astound': 7.254981992560465,\n",
       " 'astralwerk': 8.4589547968864,\n",
       " 'astray': 8.4589547968864,\n",
       " 'astro': 7.360342508218292,\n",
       " 'astrolog': 8.864419904994566,\n",
       " 'astronaut': 7.360342508218292,\n",
       " 'astronom': 8.4589547968864,\n",
       " 'astronomi': 8.864419904994566,\n",
       " 'astrophysicist': 8.864419904994566,\n",
       " 'asus': 8.864419904994566,\n",
       " 'asylum': 7.611656936499197,\n",
       " 'asymmetr': 8.4589547968864,\n",
       " 'asynchron': 8.864419904994566,\n",
       " 'at': 4.830179266842171,\n",
       " 'atamanuik': 8.864419904994566,\n",
       " 'atari': 8.864419904994566,\n",
       " 'ate': 7.07266043576651,\n",
       " 'athen': 8.171272724434619,\n",
       " 'athenian': 8.171272724434619,\n",
       " 'athlet': 6.33869126068631,\n",
       " 'atienza': 7.4781255438746745,\n",
       " 'atkin': 8.864419904994566,\n",
       " 'atkinson': 8.864419904994566,\n",
       " 'atl': 7.94812917312041,\n",
       " 'atlant': 6.561834812000519,\n",
       " 'atlanta': 6.299470547533029,\n",
       " 'atlanti': 8.4589547968864,\n",
       " 'atlas': 8.864419904994566,\n",
       " 'atleast': 8.864419904994566,\n",
       " 'atmospher': 7.765807616326455,\n",
       " 'atom': 8.171272724434619,\n",
       " 'aton': 8.4589547968864,\n",
       " 'atop': 8.4589547968864,\n",
       " 'atoradero': 8.864419904994566,\n",
       " 'atrativo': 8.864419904994566,\n",
       " 'atreo': 8.4589547968864,\n",
       " 'atreus': 8.864419904994566,\n",
       " 'att': 8.171272724434619,\n",
       " 'attaboy': 8.171272724434619,\n",
       " 'attach': 6.422072869625361,\n",
       " 'attack': 6.784978363314729,\n",
       " 'attain': 8.864419904994566,\n",
       " 'attaint': 8.864419904994566,\n",
       " 'attempt': 5.200858258864919,\n",
       " 'attend': 6.918509755939252,\n",
       " 'attent': 6.002219024065097,\n",
       " 'atticus': 8.4589547968864,\n",
       " 'attitud': 7.94812917312041,\n",
       " 'attn': 7.94812917312041,\n",
       " 'attorney': 7.94812917312041,\n",
       " 'attract': 7.4781255438746745,\n",
       " 'attribut': 5.200858258864919,\n",
       " 'atuchin': 7.94812917312041,\n",
       " 'atv': 7.15967181275614,\n",
       " 'atwel': 8.171272724434619,\n",
       " 'atwood': 7.611656936499197,\n",
       " 'atzichi': 8.4589547968864,\n",
       " 'au': 7.94812917312041,\n",
       " 'aubert': 8.4589547968864,\n",
       " 'auburn': 7.360342508218292,\n",
       " 'auckland': 7.611656936499197,\n",
       " 'aucoin': 7.4781255438746745,\n",
       " 'auction': 7.94812917312041,\n",
       " 'audi': 8.171272724434619,\n",
       " 'audibl': 6.8495168844523,\n",
       " 'audienc': 5.46322252333241,\n",
       " 'audiencesport': 8.864419904994566,\n",
       " 'audio': 4.705536821634894,\n",
       " 'audioblock': 5.750904595784191,\n",
       " 'audiobook': 6.918509755939252,\n",
       " 'audioboom': 8.864419904994566,\n",
       " 'audiojungl': 8.4589547968864,\n",
       " 'audiomachin': 8.864419904994566,\n",
       " 'audionautix': 6.667195327658346,\n",
       " 'audionetwork': 7.4781255438746745,\n",
       " 'audit': 6.33869126068631,\n",
       " 'auditorium': 8.171272724434619,\n",
       " 'audrey': 7.94812917312041,\n",
       " 'auf': 8.171272724434619,\n",
       " 'aufiero': 8.171272724434619,\n",
       " 'augment': 8.4589547968864,\n",
       " 'august': 6.918509755939252,\n",
       " 'augustus': 8.4589547968864,\n",
       " 'aulani': 8.864419904994566,\n",
       " 'aumentando': 8.864419904994566,\n",
       " 'aundrea': 8.4589547968864,\n",
       " 'aunt': 8.4589547968864,\n",
       " ...}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vect(list_of_sentence):\n",
    "    tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "    row=0;\n",
    "    for sent in tqdm(list_of_sentence): # for each review/sentence \n",
    "        sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "        weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "        for word in sent: # for each word in a review/sentence\n",
    "            if word in w2v_words and word in tfidf_feat:\n",
    "                vec = w2v_model.wv[word]\n",
    "    #             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "                # to reduce the computation we are \n",
    "                # dictionary[word] = idf value of word in whole courpus\n",
    "                # sent.count(word)/len(sent) = tf valeus of word in this review\n",
    "                tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "                sent_vec += (vec * tf_idf)\n",
    "                weight_sum += tf_idf\n",
    "        if weight_sum != 0:\n",
    "            sent_vec /= weight_sum\n",
    "        tfidf_sent_vectors.append(sent_vec)\n",
    "        row += 1\n",
    "    return  tfidf_sent_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 5205/5205 [03:56<00:00, 22.00it/s]\n"
     ]
    }
   ],
   "source": [
    "converted_desc=convert_to_vect(prepro_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.38320018, -0.19652928, -0.3863303 , -0.59279655, -0.0616388 ,\n",
       "        0.38692443,  0.30647993, -0.48602998, -0.43550448, -0.2442853 ,\n",
       "       -0.52383458, -0.54494141,  0.5453809 , -0.49372954,  0.05085436,\n",
       "       -0.21808214, -0.35588539,  0.30327882, -0.05943682,  0.17647891,\n",
       "       -0.38719636,  0.2242403 , -0.14749961, -0.06454912, -0.7079166 ,\n",
       "       -0.18082333,  0.60364602, -0.4941105 ,  0.26702948, -0.64368711,\n",
       "        0.50771972, -0.48450564,  0.25648136,  0.00127976,  0.73417286,\n",
       "        0.51418356,  0.15043556,  0.18081702,  0.3166587 , -0.16261187,\n",
       "        0.81390821,  0.36850896,  0.27880842,  0.04817512,  0.75004592,\n",
       "        1.010025  , -0.5724919 ,  0.17197365, -0.31621069,  0.84393763])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "converted_desc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data=pd.DataFrame(data=converted_desc,columns=list(np.arange(50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.383200</td>\n",
       "      <td>-0.196529</td>\n",
       "      <td>-0.386330</td>\n",
       "      <td>-0.592797</td>\n",
       "      <td>-0.061639</td>\n",
       "      <td>0.386924</td>\n",
       "      <td>0.306480</td>\n",
       "      <td>-0.486030</td>\n",
       "      <td>-0.435504</td>\n",
       "      <td>-0.244285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.813908</td>\n",
       "      <td>0.368509</td>\n",
       "      <td>0.278808</td>\n",
       "      <td>0.048175</td>\n",
       "      <td>0.750046</td>\n",
       "      <td>1.010025</td>\n",
       "      <td>-0.572492</td>\n",
       "      <td>0.171974</td>\n",
       "      <td>-0.316211</td>\n",
       "      <td>0.843938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.758918</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>-0.138680</td>\n",
       "      <td>-0.782859</td>\n",
       "      <td>-0.169357</td>\n",
       "      <td>-0.014748</td>\n",
       "      <td>-0.106402</td>\n",
       "      <td>-0.220189</td>\n",
       "      <td>-0.470053</td>\n",
       "      <td>0.102827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.697709</td>\n",
       "      <td>-0.048158</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.076451</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.331237</td>\n",
       "      <td>-0.317391</td>\n",
       "      <td>0.311603</td>\n",
       "      <td>-0.168856</td>\n",
       "      <td>0.870280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.420712</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.280512</td>\n",
       "      <td>0.184933</td>\n",
       "      <td>0.068497</td>\n",
       "      <td>0.202630</td>\n",
       "      <td>-0.281741</td>\n",
       "      <td>-0.290773</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>0.050769</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.216747</td>\n",
       "      <td>0.453705</td>\n",
       "      <td>-0.523097</td>\n",
       "      <td>-0.193434</td>\n",
       "      <td>-0.392679</td>\n",
       "      <td>0.665376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.119354</td>\n",
       "      <td>-0.212743</td>\n",
       "      <td>-0.162561</td>\n",
       "      <td>-0.190108</td>\n",
       "      <td>-0.077359</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.530475</td>\n",
       "      <td>-0.341664</td>\n",
       "      <td>-0.162481</td>\n",
       "      <td>-0.246350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.507028</td>\n",
       "      <td>0.552979</td>\n",
       "      <td>0.262707</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.564631</td>\n",
       "      <td>1.004921</td>\n",
       "      <td>-0.465219</td>\n",
       "      <td>0.192733</td>\n",
       "      <td>-0.436280</td>\n",
       "      <td>0.743820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.427602</td>\n",
       "      <td>-0.388004</td>\n",
       "      <td>-0.639915</td>\n",
       "      <td>-0.502399</td>\n",
       "      <td>-0.227805</td>\n",
       "      <td>0.226666</td>\n",
       "      <td>0.581628</td>\n",
       "      <td>0.095275</td>\n",
       "      <td>-0.389274</td>\n",
       "      <td>-0.060360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698895</td>\n",
       "      <td>0.523891</td>\n",
       "      <td>-0.582032</td>\n",
       "      <td>0.068006</td>\n",
       "      <td>0.806417</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>-0.372086</td>\n",
       "      <td>0.060332</td>\n",
       "      <td>-0.455650</td>\n",
       "      <td>0.363492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>-0.453293</td>\n",
       "      <td>0.054549</td>\n",
       "      <td>-0.364910</td>\n",
       "      <td>-0.408095</td>\n",
       "      <td>0.233459</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.205805</td>\n",
       "      <td>0.049746</td>\n",
       "      <td>-0.602240</td>\n",
       "      <td>-0.362431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.344625</td>\n",
       "      <td>0.013569</td>\n",
       "      <td>-0.207983</td>\n",
       "      <td>0.109638</td>\n",
       "      <td>0.639586</td>\n",
       "      <td>0.664816</td>\n",
       "      <td>-0.793398</td>\n",
       "      <td>0.208866</td>\n",
       "      <td>-0.198751</td>\n",
       "      <td>0.672631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>-0.301372</td>\n",
       "      <td>-0.028212</td>\n",
       "      <td>-0.204557</td>\n",
       "      <td>-0.372926</td>\n",
       "      <td>0.345677</td>\n",
       "      <td>0.135879</td>\n",
       "      <td>0.127904</td>\n",
       "      <td>-0.430649</td>\n",
       "      <td>-0.301747</td>\n",
       "      <td>-0.321363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279433</td>\n",
       "      <td>0.155025</td>\n",
       "      <td>0.284018</td>\n",
       "      <td>0.169718</td>\n",
       "      <td>0.585952</td>\n",
       "      <td>0.696843</td>\n",
       "      <td>-0.604049</td>\n",
       "      <td>0.139850</td>\n",
       "      <td>-0.398198</td>\n",
       "      <td>0.741773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>-0.019535</td>\n",
       "      <td>-0.395818</td>\n",
       "      <td>-0.192331</td>\n",
       "      <td>-0.065293</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>0.498789</td>\n",
       "      <td>0.710616</td>\n",
       "      <td>-0.378450</td>\n",
       "      <td>-0.283066</td>\n",
       "      <td>-0.386407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600285</td>\n",
       "      <td>0.691266</td>\n",
       "      <td>0.323906</td>\n",
       "      <td>0.186792</td>\n",
       "      <td>0.822797</td>\n",
       "      <td>1.162722</td>\n",
       "      <td>-0.766456</td>\n",
       "      <td>0.085529</td>\n",
       "      <td>-0.301507</td>\n",
       "      <td>0.662527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>-0.309146</td>\n",
       "      <td>-0.111109</td>\n",
       "      <td>-0.101919</td>\n",
       "      <td>-0.157381</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>0.235444</td>\n",
       "      <td>0.273420</td>\n",
       "      <td>-0.473901</td>\n",
       "      <td>-0.268255</td>\n",
       "      <td>-0.232183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.451067</td>\n",
       "      <td>0.270815</td>\n",
       "      <td>0.351265</td>\n",
       "      <td>0.191840</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.688284</td>\n",
       "      <td>-0.647587</td>\n",
       "      <td>0.075750</td>\n",
       "      <td>-0.520514</td>\n",
       "      <td>0.827787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>-0.340032</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>-0.080716</td>\n",
       "      <td>-0.374096</td>\n",
       "      <td>-0.032059</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>-0.196175</td>\n",
       "      <td>-0.223696</td>\n",
       "      <td>0.018549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.297072</td>\n",
       "      <td>0.051679</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>-0.018155</td>\n",
       "      <td>0.147573</td>\n",
       "      <td>0.349229</td>\n",
       "      <td>-0.231095</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>-0.113107</td>\n",
       "      <td>0.564318</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2         3         4         5         6   \\\n",
       "0    -0.383200 -0.196529 -0.386330 -0.592797 -0.061639  0.386924  0.306480   \n",
       "1    -0.758918  0.106050 -0.138680 -0.782859 -0.169357 -0.014748 -0.106402   \n",
       "2    -0.420712  0.001701 -0.004397 -0.280512  0.184933  0.068497  0.202630   \n",
       "3    -0.119354 -0.212743 -0.162561 -0.190108 -0.077359  0.437628  0.530475   \n",
       "4    -0.427602 -0.388004 -0.639915 -0.502399 -0.227805  0.226666  0.581628   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5200 -0.453293  0.054549 -0.364910 -0.408095  0.233459  0.013928  0.205805   \n",
       "5201 -0.301372 -0.028212 -0.204557 -0.372926  0.345677  0.135879  0.127904   \n",
       "5202 -0.019535 -0.395818 -0.192331 -0.065293 -0.001080  0.498789  0.710616   \n",
       "5203 -0.309146 -0.111109 -0.101919 -0.157381  0.066458  0.235444  0.273420   \n",
       "5204 -0.340032  0.026202 -0.080716 -0.374096 -0.032059  0.093831  0.076431   \n",
       "\n",
       "            7         8         9   ...        40        41        42  \\\n",
       "0    -0.486030 -0.435504 -0.244285  ...  0.813908  0.368509  0.278808   \n",
       "1    -0.220189 -0.470053  0.102827  ...  0.697709 -0.048158  0.098161   \n",
       "2    -0.281741 -0.290773  0.017111  ...  0.063357  0.050769  0.018184   \n",
       "3    -0.341664 -0.162481 -0.246350  ...  0.507028  0.552979  0.262707   \n",
       "4     0.095275 -0.389274 -0.060360  ...  0.698895  0.523891 -0.582032   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5200  0.049746 -0.602240 -0.362431  ...  0.344625  0.013569 -0.207983   \n",
       "5201 -0.430649 -0.301747 -0.321363  ...  0.279433  0.155025  0.284018   \n",
       "5202 -0.378450 -0.283066 -0.386407  ...  0.600285  0.691266  0.323906   \n",
       "5203 -0.473901 -0.268255 -0.232183  ...  0.451067  0.270815  0.351265   \n",
       "5204 -0.196175 -0.223696  0.018549  ...  0.297072  0.051679  0.198113   \n",
       "\n",
       "            43        44        45        46        47        48        49  \n",
       "0     0.048175  0.750046  1.010025 -0.572492  0.171974 -0.316211  0.843938  \n",
       "1     0.076451  0.165794  0.331237 -0.317391  0.311603 -0.168856  0.870280  \n",
       "2     0.053537  0.216747  0.453705 -0.523097 -0.193434 -0.392679  0.665376  \n",
       "3     0.011461  0.564631  1.004921 -0.465219  0.192733 -0.436280  0.743820  \n",
       "4     0.068006  0.806417  0.998860 -0.372086  0.060332 -0.455650  0.363492  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5200  0.109638  0.639586  0.664816 -0.793398  0.208866 -0.198751  0.672631  \n",
       "5201  0.169718  0.585952  0.696843 -0.604049  0.139850 -0.398198  0.741773  \n",
       "5202  0.186792  0.822797  1.162722 -0.766456  0.085529 -0.301507  0.662527  \n",
       "5203  0.191840  0.476640  0.688284 -0.647587  0.075750 -0.520514  0.827787  \n",
       "5204 -0.018155  0.147573  0.349229 -0.231095  0.052704 -0.113107  0.564318  \n",
       "\n",
       "[5205 rows x 50 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5205"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "conn=sqlite3.connect('tfidf_w2v.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory=str\n",
    "new_data.to_sql('Description',conn,if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['category_id']=data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data['video_id']=data['transformed_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>category_id</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.383200</td>\n",
       "      <td>-0.196529</td>\n",
       "      <td>-0.386330</td>\n",
       "      <td>-0.592797</td>\n",
       "      <td>-0.061639</td>\n",
       "      <td>0.386924</td>\n",
       "      <td>0.306480</td>\n",
       "      <td>-0.486030</td>\n",
       "      <td>-0.435504</td>\n",
       "      <td>-0.244285</td>\n",
       "      <td>...</td>\n",
       "      <td>0.278808</td>\n",
       "      <td>0.048175</td>\n",
       "      <td>0.750046</td>\n",
       "      <td>1.010025</td>\n",
       "      <td>-0.572492</td>\n",
       "      <td>0.171974</td>\n",
       "      <td>-0.316211</td>\n",
       "      <td>0.843938</td>\n",
       "      <td>0</td>\n",
       "      <td>515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.758918</td>\n",
       "      <td>0.106050</td>\n",
       "      <td>-0.138680</td>\n",
       "      <td>-0.782859</td>\n",
       "      <td>-0.169357</td>\n",
       "      <td>-0.014748</td>\n",
       "      <td>-0.106402</td>\n",
       "      <td>-0.220189</td>\n",
       "      <td>-0.470053</td>\n",
       "      <td>0.102827</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098161</td>\n",
       "      <td>0.076451</td>\n",
       "      <td>0.165794</td>\n",
       "      <td>0.331237</td>\n",
       "      <td>-0.317391</td>\n",
       "      <td>0.311603</td>\n",
       "      <td>-0.168856</td>\n",
       "      <td>0.870280</td>\n",
       "      <td>1</td>\n",
       "      <td>1420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.420712</td>\n",
       "      <td>0.001701</td>\n",
       "      <td>-0.004397</td>\n",
       "      <td>-0.280512</td>\n",
       "      <td>0.184933</td>\n",
       "      <td>0.068497</td>\n",
       "      <td>0.202630</td>\n",
       "      <td>-0.281741</td>\n",
       "      <td>-0.290773</td>\n",
       "      <td>0.017111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018184</td>\n",
       "      <td>0.053537</td>\n",
       "      <td>0.216747</td>\n",
       "      <td>0.453705</td>\n",
       "      <td>-0.523097</td>\n",
       "      <td>-0.193434</td>\n",
       "      <td>-0.392679</td>\n",
       "      <td>0.665376</td>\n",
       "      <td>2</td>\n",
       "      <td>2292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.119354</td>\n",
       "      <td>-0.212743</td>\n",
       "      <td>-0.162561</td>\n",
       "      <td>-0.190108</td>\n",
       "      <td>-0.077359</td>\n",
       "      <td>0.437628</td>\n",
       "      <td>0.530475</td>\n",
       "      <td>-0.341664</td>\n",
       "      <td>-0.162481</td>\n",
       "      <td>-0.246350</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262707</td>\n",
       "      <td>0.011461</td>\n",
       "      <td>0.564631</td>\n",
       "      <td>1.004921</td>\n",
       "      <td>-0.465219</td>\n",
       "      <td>0.192733</td>\n",
       "      <td>-0.436280</td>\n",
       "      <td>0.743820</td>\n",
       "      <td>3</td>\n",
       "      <td>1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.427602</td>\n",
       "      <td>-0.388004</td>\n",
       "      <td>-0.639915</td>\n",
       "      <td>-0.502399</td>\n",
       "      <td>-0.227805</td>\n",
       "      <td>0.226666</td>\n",
       "      <td>0.581628</td>\n",
       "      <td>0.095275</td>\n",
       "      <td>-0.389274</td>\n",
       "      <td>-0.060360</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.582032</td>\n",
       "      <td>0.068006</td>\n",
       "      <td>0.806417</td>\n",
       "      <td>0.998860</td>\n",
       "      <td>-0.372086</td>\n",
       "      <td>0.060332</td>\n",
       "      <td>-0.455650</td>\n",
       "      <td>0.363492</td>\n",
       "      <td>1</td>\n",
       "      <td>2522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5200</th>\n",
       "      <td>-0.453293</td>\n",
       "      <td>0.054549</td>\n",
       "      <td>-0.364910</td>\n",
       "      <td>-0.408095</td>\n",
       "      <td>0.233459</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.205805</td>\n",
       "      <td>0.049746</td>\n",
       "      <td>-0.602240</td>\n",
       "      <td>-0.362431</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.207983</td>\n",
       "      <td>0.109638</td>\n",
       "      <td>0.639586</td>\n",
       "      <td>0.664816</td>\n",
       "      <td>-0.793398</td>\n",
       "      <td>0.208866</td>\n",
       "      <td>-0.198751</td>\n",
       "      <td>0.672631</td>\n",
       "      <td>11</td>\n",
       "      <td>648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5201</th>\n",
       "      <td>-0.301372</td>\n",
       "      <td>-0.028212</td>\n",
       "      <td>-0.204557</td>\n",
       "      <td>-0.372926</td>\n",
       "      <td>0.345677</td>\n",
       "      <td>0.135879</td>\n",
       "      <td>0.127904</td>\n",
       "      <td>-0.430649</td>\n",
       "      <td>-0.301747</td>\n",
       "      <td>-0.321363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284018</td>\n",
       "      <td>0.169718</td>\n",
       "      <td>0.585952</td>\n",
       "      <td>0.696843</td>\n",
       "      <td>-0.604049</td>\n",
       "      <td>0.139850</td>\n",
       "      <td>-0.398198</td>\n",
       "      <td>0.741773</td>\n",
       "      <td>2</td>\n",
       "      <td>565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5202</th>\n",
       "      <td>-0.019535</td>\n",
       "      <td>-0.395818</td>\n",
       "      <td>-0.192331</td>\n",
       "      <td>-0.065293</td>\n",
       "      <td>-0.001080</td>\n",
       "      <td>0.498789</td>\n",
       "      <td>0.710616</td>\n",
       "      <td>-0.378450</td>\n",
       "      <td>-0.283066</td>\n",
       "      <td>-0.386407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.323906</td>\n",
       "      <td>0.186792</td>\n",
       "      <td>0.822797</td>\n",
       "      <td>1.162722</td>\n",
       "      <td>-0.766456</td>\n",
       "      <td>0.085529</td>\n",
       "      <td>-0.301507</td>\n",
       "      <td>0.662527</td>\n",
       "      <td>4</td>\n",
       "      <td>1123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5203</th>\n",
       "      <td>-0.309146</td>\n",
       "      <td>-0.111109</td>\n",
       "      <td>-0.101919</td>\n",
       "      <td>-0.157381</td>\n",
       "      <td>0.066458</td>\n",
       "      <td>0.235444</td>\n",
       "      <td>0.273420</td>\n",
       "      <td>-0.473901</td>\n",
       "      <td>-0.268255</td>\n",
       "      <td>-0.232183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351265</td>\n",
       "      <td>0.191840</td>\n",
       "      <td>0.476640</td>\n",
       "      <td>0.688284</td>\n",
       "      <td>-0.647587</td>\n",
       "      <td>0.075750</td>\n",
       "      <td>-0.520514</td>\n",
       "      <td>0.827787</td>\n",
       "      <td>3</td>\n",
       "      <td>1764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>-0.340032</td>\n",
       "      <td>0.026202</td>\n",
       "      <td>-0.080716</td>\n",
       "      <td>-0.374096</td>\n",
       "      <td>-0.032059</td>\n",
       "      <td>0.093831</td>\n",
       "      <td>0.076431</td>\n",
       "      <td>-0.196175</td>\n",
       "      <td>-0.223696</td>\n",
       "      <td>0.018549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>-0.018155</td>\n",
       "      <td>0.147573</td>\n",
       "      <td>0.349229</td>\n",
       "      <td>-0.231095</td>\n",
       "      <td>0.052704</td>\n",
       "      <td>-0.113107</td>\n",
       "      <td>0.564318</td>\n",
       "      <td>9</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5205 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.383200 -0.196529 -0.386330 -0.592797 -0.061639  0.386924  0.306480   \n",
       "1    -0.758918  0.106050 -0.138680 -0.782859 -0.169357 -0.014748 -0.106402   \n",
       "2    -0.420712  0.001701 -0.004397 -0.280512  0.184933  0.068497  0.202630   \n",
       "3    -0.119354 -0.212743 -0.162561 -0.190108 -0.077359  0.437628  0.530475   \n",
       "4    -0.427602 -0.388004 -0.639915 -0.502399 -0.227805  0.226666  0.581628   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5200 -0.453293  0.054549 -0.364910 -0.408095  0.233459  0.013928  0.205805   \n",
       "5201 -0.301372 -0.028212 -0.204557 -0.372926  0.345677  0.135879  0.127904   \n",
       "5202 -0.019535 -0.395818 -0.192331 -0.065293 -0.001080  0.498789  0.710616   \n",
       "5203 -0.309146 -0.111109 -0.101919 -0.157381  0.066458  0.235444  0.273420   \n",
       "5204 -0.340032  0.026202 -0.080716 -0.374096 -0.032059  0.093831  0.076431   \n",
       "\n",
       "             7         8         9  ...        42        43        44  \\\n",
       "0    -0.486030 -0.435504 -0.244285  ...  0.278808  0.048175  0.750046   \n",
       "1    -0.220189 -0.470053  0.102827  ...  0.098161  0.076451  0.165794   \n",
       "2    -0.281741 -0.290773  0.017111  ...  0.018184  0.053537  0.216747   \n",
       "3    -0.341664 -0.162481 -0.246350  ...  0.262707  0.011461  0.564631   \n",
       "4     0.095275 -0.389274 -0.060360  ... -0.582032  0.068006  0.806417   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5200  0.049746 -0.602240 -0.362431  ... -0.207983  0.109638  0.639586   \n",
       "5201 -0.430649 -0.301747 -0.321363  ...  0.284018  0.169718  0.585952   \n",
       "5202 -0.378450 -0.283066 -0.386407  ...  0.323906  0.186792  0.822797   \n",
       "5203 -0.473901 -0.268255 -0.232183  ...  0.351265  0.191840  0.476640   \n",
       "5204 -0.196175 -0.223696  0.018549  ...  0.198113 -0.018155  0.147573   \n",
       "\n",
       "            45        46        47        48        49  category_id  video_id  \n",
       "0     1.010025 -0.572492  0.171974 -0.316211  0.843938            0       515  \n",
       "1     0.331237 -0.317391  0.311603 -0.168856  0.870280            1      1420  \n",
       "2     0.453705 -0.523097 -0.193434 -0.392679  0.665376            2      2292  \n",
       "3     1.004921 -0.465219  0.192733 -0.436280  0.743820            3      1046  \n",
       "4     0.998860 -0.372086  0.060332 -0.455650  0.363492            1      2522  \n",
       "...        ...       ...       ...       ...       ...          ...       ...  \n",
       "5200  0.664816 -0.793398  0.208866 -0.198751  0.672631           11       648  \n",
       "5201  0.696843 -0.604049  0.139850 -0.398198  0.741773            2       565  \n",
       "5202  1.162722 -0.766456  0.085529 -0.301507  0.662527            4      1123  \n",
       "5203  0.688284 -0.647587  0.075750 -0.520514  0.827787            3      1764  \n",
       "5204  0.349229 -0.231095  0.052704 -0.113107  0.564318            9       118  \n",
       "\n",
       "[5205 rows x 52 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=new_data.drop('category_id',axis=1)\n",
    "Y=new_data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5205, 51), (5205,))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3487, 51), (1718, 51))"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring(model,X_test,Y_test):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=3.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    }
   ],
   "source": [
    "myList = list(range(0,100))\n",
    "neighbors = list(filter(lambda x: x % 2 != 0, myList))\n",
    "\n",
    "cv_scores = []\n",
    "for k in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train, Y_train, cv=3, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.45712539384907275,\n",
       " 0.31001046317686914,\n",
       " 0.2583871908220032,\n",
       " 0.25035925547170873,\n",
       " 0.2434767937984588,\n",
       " 0.23229510598591394,\n",
       " 0.23086030400930588,\n",
       " 0.23171990258047295,\n",
       " 0.23057294896327726,\n",
       " 0.22368950066325985,\n",
       " 0.22684423975227774,\n",
       " 0.22139485345879276,\n",
       " 0.21766861081471198,\n",
       " 0.22627051628698802,\n",
       " 0.22914012024020414,\n",
       " 0.2228291621220171,\n",
       " 0.2234041188707662,\n",
       " 0.22512306935640858,\n",
       " 0.22196931689415814,\n",
       " 0.22512479595325166,\n",
       " 0.22541141102920462,\n",
       " 0.2274196898144106,\n",
       " 0.23057270230658541,\n",
       " 0.23229263941899522,\n",
       " 0.23085882406915462,\n",
       " 0.23458753328015416,\n",
       " 0.23745491732314347,\n",
       " 0.23917608771901266,\n",
       " 0.24089602483142247,\n",
       " 0.2391748544355533,\n",
       " 0.24060891644208574,\n",
       " 0.23774128574240458,\n",
       " 0.24204273179192634,\n",
       " 0.24232934686787932,\n",
       " 0.24089553151803875,\n",
       " 0.24232910021118745,\n",
       " 0.24175685668604893,\n",
       " 0.2420439650753857,\n",
       " 0.2408967648014981,\n",
       " 0.23774227236917203,\n",
       " 0.2408975047715737,\n",
       " 0.23831599583446175,\n",
       " 0.23860236425372292,\n",
       " 0.23888848601629217,\n",
       " 0.2397478379307674,\n",
       " 0.24032057476928967,\n",
       " 0.24118091331053237,\n",
       " 0.24175439011913025,\n",
       " 0.24032008145590592,\n",
       " 0.23974586467723244]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn=KNeighborsClassifier(n_neighbors=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5675203725261933"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56.89464559875934"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=knn.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Logistic Regresssion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=LogisticRegression(multi_class='multinomial',solver='lbfgs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28346915017462165"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.34535522645495"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lr.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "tuned_param=[{'C':[10**-4,10**-2, 10**0, 10**2, 10**4]}]\n",
    "lr_gs=GridSearchCV(LogisticRegression(multi_class='multinomial',solver='lbfgs'),tuned_param,scoring='f1_micro',cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(multi_class='multinomial'),\n",
       "             param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
       "             scoring='f1_micro')"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2729918509895227"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_gs.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.54714791034957"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=lr_gs.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc=DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142025611175786"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.25758259859906"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=dtc.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Decision tree with grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper=[{'max_depth':[2,3,5,7]}]\n",
    "dtc_gs=GridSearchCV(dtc,hyper,scoring='f1_weighted',cv=5,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:670: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn((\"The least populated class in y has only %d\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid=[{'max_depth': [2, 3, 5, 7]}], scoring='f1_weighted')"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_gs.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3700056606797851"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtc_gs.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.00056606797851"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=dtc_gs.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23806752037252618"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, Y_train)\n",
    "gnb.score(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.347894363882947"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred=gnb.predict(X_test)\n",
    "100*metrics.f1_score(Y_test,pred,average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So after all decision tree did the best job so far"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfNzMKvoVOU</td>\n",
       "      <td>States are taking a multi-million dollar gambl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PjqKPHZJgF0</td>\n",
       "      <td>Family Feud by Lil Wayne feat. Drake, off the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KobCmaF10vQ</td>\n",
       "      <td>Black Nerd Review of Black Lightning Episode 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D_ZODCSKXo</td>\n",
       "      <td>On this episode of Collider Movie Talk (Wednes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6kyXZGyso8M</td>\n",
       "      <td>Alabama head coach Nick Saban, freshman quarte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>ObvUP5YxAKg</td>\n",
       "      <td>7th-grader shoots himself at Jackson Memorial ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>YvEGAcgpwqQ</td>\n",
       "      <td>To Kevin Hart, they’re not partner push-ups—th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>tYF1dQRVS2c</td>\n",
       "      <td>Grab the RECIPE here: http://thescranline.com\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>B2YCf8dTkIM</td>\n",
       "      <td>Use my link http://www.audible.com/forge , or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>cQtYcpRGGIY</td>\n",
       "      <td>🌼Visit http://SeonkyoungLongest.com for Writte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id                                        description\n",
       "0     tfNzMKvoVOU  States are taking a multi-million dollar gambl...\n",
       "1     PjqKPHZJgF0  Family Feud by Lil Wayne feat. Drake, off the ...\n",
       "2     KobCmaF10vQ  Black Nerd Review of Black Lightning Episode 1...\n",
       "3     3D_ZODCSKXo  On this episode of Collider Movie Talk (Wednes...\n",
       "4     6kyXZGyso8M  Alabama head coach Nick Saban, freshman quarte...\n",
       "...           ...                                                ...\n",
       "2227  ObvUP5YxAKg  7th-grader shoots himself at Jackson Memorial ...\n",
       "2228  YvEGAcgpwqQ  To Kevin Hart, they’re not partner push-ups—th...\n",
       "2229  tYF1dQRVS2c  Grab the RECIPE here: http://thescranline.com\\...\n",
       "2230  B2YCf8dTkIM  Use my link http://www.audible.com/forge , or ...\n",
       "2231  cQtYcpRGGIY  🌼Visit http://SeonkyoungLongest.com for Writte...\n",
       "\n",
       "[2232 rows x 2 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_id_test=le.fit_transform(test_data['video_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['transformed_id']=trans_id_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552     4\n",
       "1762    4\n",
       "484     4\n",
       "167     4\n",
       "980     4\n",
       "       ..\n",
       "909     1\n",
       "1112    1\n",
       "1580    1\n",
       "830     1\n",
       "1637    1\n",
       "Name: transformed_id, Length: 1790, dtype: int64"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['transformed_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_text2=[]\n",
    "for sent in test_data['description']:\n",
    "    temp_str=re.sub(r\"http\\S+\",\" \",sent)\n",
    "    temp_str=re.sub(r\"www\\S+\",\" \",temp_str)\n",
    "    new_text2.append(temp_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences2=pd.Series(new_text2)\n",
    "prepro_text2=preprocess2(sentences2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 2232/2232 [01:26<00:00, 25.94it/s]\n"
     ]
    }
   ],
   "source": [
    "converted_desc2=convert_to_vect(prepro_text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_test=pd.DataFrame(data=converted_desc2,columns=list(np.arange(50)))\n",
    "new_data_test['video_id']=test_data['transformed_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.360126</td>\n",
       "      <td>-0.020581</td>\n",
       "      <td>-0.065819</td>\n",
       "      <td>-0.324184</td>\n",
       "      <td>0.044485</td>\n",
       "      <td>0.140296</td>\n",
       "      <td>0.293537</td>\n",
       "      <td>-0.202045</td>\n",
       "      <td>-0.274519</td>\n",
       "      <td>-0.083301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134494</td>\n",
       "      <td>0.239950</td>\n",
       "      <td>-0.056747</td>\n",
       "      <td>0.306519</td>\n",
       "      <td>0.526447</td>\n",
       "      <td>-0.430059</td>\n",
       "      <td>-0.081085</td>\n",
       "      <td>-0.289557</td>\n",
       "      <td>0.656364</td>\n",
       "      <td>1640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.254568</td>\n",
       "      <td>-0.201017</td>\n",
       "      <td>-0.449679</td>\n",
       "      <td>-0.407488</td>\n",
       "      <td>0.134840</td>\n",
       "      <td>0.230253</td>\n",
       "      <td>0.292275</td>\n",
       "      <td>-0.052290</td>\n",
       "      <td>-0.426687</td>\n",
       "      <td>-0.191558</td>\n",
       "      <td>...</td>\n",
       "      <td>0.249861</td>\n",
       "      <td>-0.243080</td>\n",
       "      <td>0.061736</td>\n",
       "      <td>0.691784</td>\n",
       "      <td>0.848560</td>\n",
       "      <td>-0.559013</td>\n",
       "      <td>0.226709</td>\n",
       "      <td>-0.224714</td>\n",
       "      <td>0.315794</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.286823</td>\n",
       "      <td>-0.117750</td>\n",
       "      <td>-0.124536</td>\n",
       "      <td>-0.359360</td>\n",
       "      <td>-0.253424</td>\n",
       "      <td>0.114651</td>\n",
       "      <td>0.390886</td>\n",
       "      <td>-0.114399</td>\n",
       "      <td>-0.312973</td>\n",
       "      <td>0.034620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.346305</td>\n",
       "      <td>0.083133</td>\n",
       "      <td>0.016347</td>\n",
       "      <td>0.293489</td>\n",
       "      <td>0.559862</td>\n",
       "      <td>-0.242215</td>\n",
       "      <td>0.176826</td>\n",
       "      <td>-0.045925</td>\n",
       "      <td>0.535092</td>\n",
       "      <td>629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.305827</td>\n",
       "      <td>-0.247973</td>\n",
       "      <td>-0.044502</td>\n",
       "      <td>-0.238600</td>\n",
       "      <td>0.014407</td>\n",
       "      <td>0.136082</td>\n",
       "      <td>0.691167</td>\n",
       "      <td>-0.219595</td>\n",
       "      <td>-0.296616</td>\n",
       "      <td>-0.143171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.577361</td>\n",
       "      <td>-0.021062</td>\n",
       "      <td>0.090075</td>\n",
       "      <td>0.632946</td>\n",
       "      <td>0.914324</td>\n",
       "      <td>-0.527483</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>-0.184279</td>\n",
       "      <td>0.666548</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.258029</td>\n",
       "      <td>-0.038809</td>\n",
       "      <td>-0.112032</td>\n",
       "      <td>-0.274187</td>\n",
       "      <td>0.067094</td>\n",
       "      <td>0.108285</td>\n",
       "      <td>0.163924</td>\n",
       "      <td>-0.190048</td>\n",
       "      <td>-0.213058</td>\n",
       "      <td>-0.105882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113033</td>\n",
       "      <td>0.062439</td>\n",
       "      <td>-0.023375</td>\n",
       "      <td>0.304587</td>\n",
       "      <td>0.439828</td>\n",
       "      <td>-0.281287</td>\n",
       "      <td>0.066199</td>\n",
       "      <td>-0.175656</td>\n",
       "      <td>0.434371</td>\n",
       "      <td>230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>-0.495440</td>\n",
       "      <td>0.114556</td>\n",
       "      <td>0.019360</td>\n",
       "      <td>-0.367294</td>\n",
       "      <td>0.075686</td>\n",
       "      <td>-0.066740</td>\n",
       "      <td>0.074533</td>\n",
       "      <td>-0.225697</td>\n",
       "      <td>-0.192257</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045500</td>\n",
       "      <td>0.282324</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>0.096677</td>\n",
       "      <td>0.280822</td>\n",
       "      <td>-0.237709</td>\n",
       "      <td>-0.106441</td>\n",
       "      <td>-0.280972</td>\n",
       "      <td>0.725048</td>\n",
       "      <td>742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>-0.947183</td>\n",
       "      <td>0.149204</td>\n",
       "      <td>-0.102465</td>\n",
       "      <td>-0.885135</td>\n",
       "      <td>-0.335956</td>\n",
       "      <td>-0.039767</td>\n",
       "      <td>-0.101516</td>\n",
       "      <td>-0.244664</td>\n",
       "      <td>-0.508324</td>\n",
       "      <td>0.158337</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.052145</td>\n",
       "      <td>0.205568</td>\n",
       "      <td>-0.044681</td>\n",
       "      <td>0.162727</td>\n",
       "      <td>0.323914</td>\n",
       "      <td>-0.235310</td>\n",
       "      <td>0.227608</td>\n",
       "      <td>0.082454</td>\n",
       "      <td>0.948355</td>\n",
       "      <td>1002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>-0.586028</td>\n",
       "      <td>0.237538</td>\n",
       "      <td>0.034988</td>\n",
       "      <td>-0.682533</td>\n",
       "      <td>-0.097411</td>\n",
       "      <td>0.075772</td>\n",
       "      <td>-0.301778</td>\n",
       "      <td>-0.336993</td>\n",
       "      <td>-0.309727</td>\n",
       "      <td>-0.062882</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.269743</td>\n",
       "      <td>0.773289</td>\n",
       "      <td>-0.051929</td>\n",
       "      <td>0.121074</td>\n",
       "      <td>0.238277</td>\n",
       "      <td>-0.235941</td>\n",
       "      <td>0.282325</td>\n",
       "      <td>-0.090616</td>\n",
       "      <td>0.978157</td>\n",
       "      <td>1637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>-0.277778</td>\n",
       "      <td>-0.059405</td>\n",
       "      <td>-0.106143</td>\n",
       "      <td>-0.205406</td>\n",
       "      <td>0.034399</td>\n",
       "      <td>0.300906</td>\n",
       "      <td>0.232750</td>\n",
       "      <td>-0.448074</td>\n",
       "      <td>-0.236410</td>\n",
       "      <td>-0.255453</td>\n",
       "      <td>...</td>\n",
       "      <td>0.214547</td>\n",
       "      <td>0.497137</td>\n",
       "      <td>0.063896</td>\n",
       "      <td>0.516201</td>\n",
       "      <td>0.791531</td>\n",
       "      <td>-0.565644</td>\n",
       "      <td>0.043299</td>\n",
       "      <td>-0.477719</td>\n",
       "      <td>0.784852</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>-0.306929</td>\n",
       "      <td>-0.054226</td>\n",
       "      <td>-0.076727</td>\n",
       "      <td>-0.248853</td>\n",
       "      <td>-0.027501</td>\n",
       "      <td>0.270936</td>\n",
       "      <td>0.254196</td>\n",
       "      <td>-0.386815</td>\n",
       "      <td>-0.215675</td>\n",
       "      <td>-0.251001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196829</td>\n",
       "      <td>0.605789</td>\n",
       "      <td>0.037418</td>\n",
       "      <td>0.426585</td>\n",
       "      <td>0.752730</td>\n",
       "      <td>-0.530075</td>\n",
       "      <td>0.041703</td>\n",
       "      <td>-0.270235</td>\n",
       "      <td>0.848822</td>\n",
       "      <td>1122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "0    -0.360126 -0.020581 -0.065819 -0.324184  0.044485  0.140296  0.293537   \n",
       "1    -0.254568 -0.201017 -0.449679 -0.407488  0.134840  0.230253  0.292275   \n",
       "2    -0.286823 -0.117750 -0.124536 -0.359360 -0.253424  0.114651  0.390886   \n",
       "3    -0.305827 -0.247973 -0.044502 -0.238600  0.014407  0.136082  0.691167   \n",
       "4    -0.258029 -0.038809 -0.112032 -0.274187  0.067094  0.108285  0.163924   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2227 -0.495440  0.114556  0.019360 -0.367294  0.075686 -0.066740  0.074533   \n",
       "2228 -0.947183  0.149204 -0.102465 -0.885135 -0.335956 -0.039767 -0.101516   \n",
       "2229 -0.586028  0.237538  0.034988 -0.682533 -0.097411  0.075772 -0.301778   \n",
       "2230 -0.277778 -0.059405 -0.106143 -0.205406  0.034399  0.300906  0.232750   \n",
       "2231 -0.306929 -0.054226 -0.076727 -0.248853 -0.027501  0.270936  0.254196   \n",
       "\n",
       "             7         8         9  ...        41        42        43  \\\n",
       "0    -0.202045 -0.274519 -0.083301  ...  0.134494  0.239950 -0.056747   \n",
       "1    -0.052290 -0.426687 -0.191558  ...  0.249861 -0.243080  0.061736   \n",
       "2    -0.114399 -0.312973  0.034620  ...  0.346305  0.083133  0.016347   \n",
       "3    -0.219595 -0.296616 -0.143171  ...  0.577361 -0.021062  0.090075   \n",
       "4    -0.190048 -0.213058 -0.105882  ...  0.113033  0.062439 -0.023375   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "2227 -0.225697 -0.192257 -0.003885  ... -0.045500  0.282324 -0.057632   \n",
       "2228 -0.244664 -0.508324  0.158337  ... -0.052145  0.205568 -0.044681   \n",
       "2229 -0.336993 -0.309727 -0.062882  ... -0.269743  0.773289 -0.051929   \n",
       "2230 -0.448074 -0.236410 -0.255453  ...  0.214547  0.497137  0.063896   \n",
       "2231 -0.386815 -0.215675 -0.251001  ...  0.196829  0.605789  0.037418   \n",
       "\n",
       "            44        45        46        47        48        49  video_id  \n",
       "0     0.306519  0.526447 -0.430059 -0.081085 -0.289557  0.656364      1640  \n",
       "1     0.691784  0.848560 -0.559013  0.226709 -0.224714  0.315794       773  \n",
       "2     0.293489  0.559862 -0.242215  0.176826 -0.045925  0.535092       629  \n",
       "3     0.632946  0.914324 -0.527483  0.008584 -0.184279  0.666548       121  \n",
       "4     0.304587  0.439828 -0.281287  0.066199 -0.175656  0.434371       230  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "2227  0.096677  0.280822 -0.237709 -0.106441 -0.280972  0.725048       742  \n",
       "2228  0.162727  0.323914 -0.235310  0.227608  0.082454  0.948355      1002  \n",
       "2229  0.121074  0.238277 -0.235941  0.282325 -0.090616  0.978157      1637  \n",
       "2230  0.516201  0.791531 -0.565644  0.043299 -0.477719  0.784852       343  \n",
       "2231  0.426585  0.752730 -0.530075  0.041703 -0.270235  0.848822      1122  \n",
       "\n",
       "[2232 rows x 51 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=dtc.predict(new_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_test['prediction']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data=new_data_test.drop(list(np.arange(50)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data['actual_video_id']=test_data['video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data=submission_data.drop('video_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data['video_id']=submission_data['actual_video_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data=submission_data.drop('actual_video_id',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>video_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>tfNzMKvoVOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PjqKPHZJgF0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>KobCmaF10vQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3D_ZODCSKXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>6kyXZGyso8M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>2</td>\n",
       "      <td>ObvUP5YxAKg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>4</td>\n",
       "      <td>YvEGAcgpwqQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>3</td>\n",
       "      <td>tYF1dQRVS2c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>3</td>\n",
       "      <td>B2YCf8dTkIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>0</td>\n",
       "      <td>cQtYcpRGGIY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      prediction     video_id\n",
       "0              5  tfNzMKvoVOU\n",
       "1              1  PjqKPHZJgF0\n",
       "2              0  KobCmaF10vQ\n",
       "3              0  3D_ZODCSKXo\n",
       "4              2  6kyXZGyso8M\n",
       "...          ...          ...\n",
       "2227           2  ObvUP5YxAKg\n",
       "2228           4  YvEGAcgpwqQ\n",
       "2229           3  tYF1dQRVS2c\n",
       "2230           3  B2YCf8dTkIM\n",
       "2231           0  cQtYcpRGGIY\n",
       "\n",
       "[2232 rows x 2 columns]"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_key(val):\n",
    "    for key, value in temp.items():\n",
    "         if val == value:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "category=submission_data['prediction'].map(get_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data['category_id']=category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_data=submission_data.drop('prediction',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tfNzMKvoVOU</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PjqKPHZJgF0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KobCmaF10vQ</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3D_ZODCSKXo</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6kyXZGyso8M</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>ObvUP5YxAKg</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2228</th>\n",
       "      <td>YvEGAcgpwqQ</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2229</th>\n",
       "      <td>tYF1dQRVS2c</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>B2YCf8dTkIM</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>cQtYcpRGGIY</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2232 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         video_id  category_id\n",
       "0     tfNzMKvoVOU         22.0\n",
       "1     PjqKPHZJgF0         10.0\n",
       "2     KobCmaF10vQ         24.0\n",
       "3     3D_ZODCSKXo         24.0\n",
       "4     6kyXZGyso8M         25.0\n",
       "...           ...          ...\n",
       "2227  ObvUP5YxAKg         25.0\n",
       "2228  YvEGAcgpwqQ         23.0\n",
       "2229  tYF1dQRVS2c         26.0\n",
       "2230  B2YCf8dTkIM         26.0\n",
       "2231  cQtYcpRGGIY         24.0\n",
       "\n",
       "[2232 rows x 2 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'SubmissionData.csv'\n",
    "  \n",
    "# saving the excel\n",
    "submission_data.to_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
